{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torchmetrics import F1Score, Precision, Recall, Accuracy\n",
    "import torch\n",
    "from image_modalities_classifier.models.predict import ModalityPredictor, RunConfig, SingleModalityPredictor\n",
    "from os import cpu_count\n",
    "\n",
    "\n",
    "artifacts = Path(\"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/\")\n",
    "data_path = Path(\"/media/cumulus/curation_data/modality_classifiers_production/data/cord19\")\n",
    "\n",
    "classifiers = {\n",
    "    \"classifier\": \"higher-modality\",\n",
    "    \"classname\": \"\",\n",
    "    \"path\": artifacts / \"higher-modality/efficientnet-b1_higher-modality_0.pt\",\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"classifier\": \"experimental\",\n",
    "            \"classname\": \"exp\",\n",
    "            \"path\": artifacts / \"experimental/efficientnet-b1_experimental_0.pt\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"classifier\": \"gel\",\n",
    "                    \"classname\": \"exp.gel\",\n",
    "                    \"path\": artifacts / \"gel/efficientnet-b1_gel_0.pt\",\n",
    "                    \"children\": []\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"classifier\": \"graphics\",\n",
    "            \"classname\": \"gra\",\n",
    "            \"path\": artifacts / \"graphics/efficientnet-b1_graphics_0.pt\",\n",
    "            \"children\": [],\n",
    "        },\n",
    "        {\n",
    "            \"classifier\": \"microscopy\",\n",
    "            \"classname\": \"mic\",\n",
    "            \"path\": artifacts / \"microscopy/efficientnet-b0_microscopy_0.pt\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"classifier\": \"electron\",\n",
    "                    \"classname\": \"mic.ele\",\n",
    "                    \"path\": artifacts / \"electron/efficientnet-b1_electron_0.pt\",\n",
    "                    \"children\": [],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"classifier\": \"molecular\",\n",
    "            \"classname\": \"mol\",\n",
    "            \"path\": artifacts / \"molecular\" / \"efficientnet-b1_molecular_3.pt\",\n",
    "            \"children\": [],\n",
    "        },\n",
    "        {\n",
    "            \"classifier\": \"radiology\",\n",
    "            \"classname\": \"rad\",\n",
    "            \"path\": artifacts / \"radiology\" / \"efficientnet-b0_radiology_3.pt\",\n",
    "            \"children\": [],\n",
    "        },\n",
    "        {\n",
    "            \"classifier\": \"photography\",\n",
    "            \"classname\": \"pho\",\n",
    "            \"path\": artifacts / \"photography/resnet34_photography_0.pt\",\n",
    "            \"children\": []\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_path = data_path / \"cord19_molecular_v3.parquet\"\n",
    "df = pd.read_parquet(model_path)\n",
    "# df = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# config = RunConfig(32, cpu_count(), \"cuda:0\")\n",
    "\n",
    "# resnet_34 = \"/media/cumulus/curation_data/modality_classifiers/models/cord19/molecular/resnet34_molecular_3.pt\"\n",
    "# efficient = str(artifacts / \"molecular/efficientnet-b1_molecular_3.pt\")\n",
    "\n",
    "# predictor = SingleModalityPredictor(efficient, config)\n",
    "# predictor = ModalityPredictor(classifiers, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:02<00:00, 11.83it/s]\n"
     ]
    }
   ],
   "source": [
    "base_img_path = \"/media/cumulus/curation_data/\"\n",
    "predictions = predictor.predict(train_df, base_img_path)\n",
    "ground_truth = train_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "{'name': 'resnet18', 'num_classes': 4, 'pretrained': True, 'fine_tuned_from': 'whole', 'lr': 0.0001, 'class_weights': array([5.08064516, 0.4600779 , 3.28125   , 0.75479233]), 'metric_monitor': 'val_avg_loss', 'mode_scheduler': 'min', 'mean_dataset': tensor([0.3379, 0.3450, 0.3462]), 'std_dataset': tensor([0.2848, 0.2879, 0.2885])}\n",
      "odict_keys(['model.conv1.weight', 'model.bn1.weight', 'model.bn1.bias', 'model.bn1.running_mean', 'model.bn1.running_var', 'model.bn1.num_batches_tracked', 'model.layer1.0.conv1.weight', 'model.layer1.0.bn1.weight', 'model.layer1.0.bn1.bias', 'model.layer1.0.bn1.running_mean', 'model.layer1.0.bn1.running_var', 'model.layer1.0.bn1.num_batches_tracked', 'model.layer1.0.conv2.weight', 'model.layer1.0.bn2.weight', 'model.layer1.0.bn2.bias', 'model.layer1.0.bn2.running_mean', 'model.layer1.0.bn2.running_var', 'model.layer1.0.bn2.num_batches_tracked', 'model.layer1.1.conv1.weight', 'model.layer1.1.bn1.weight', 'model.layer1.1.bn1.bias', 'model.layer1.1.bn1.running_mean', 'model.layer1.1.bn1.running_var', 'model.layer1.1.bn1.num_batches_tracked', 'model.layer1.1.conv2.weight', 'model.layer1.1.bn2.weight', 'model.layer1.1.bn2.bias', 'model.layer1.1.bn2.running_mean', 'model.layer1.1.bn2.running_var', 'model.layer1.1.bn2.num_batches_tracked', 'model.layer2.0.conv1.weight', 'model.layer2.0.bn1.weight', 'model.layer2.0.bn1.bias', 'model.layer2.0.bn1.running_mean', 'model.layer2.0.bn1.running_var', 'model.layer2.0.bn1.num_batches_tracked', 'model.layer2.0.conv2.weight', 'model.layer2.0.bn2.weight', 'model.layer2.0.bn2.bias', 'model.layer2.0.bn2.running_mean', 'model.layer2.0.bn2.running_var', 'model.layer2.0.bn2.num_batches_tracked', 'model.layer2.0.downsample.0.weight', 'model.layer2.0.downsample.1.weight', 'model.layer2.0.downsample.1.bias', 'model.layer2.0.downsample.1.running_mean', 'model.layer2.0.downsample.1.running_var', 'model.layer2.0.downsample.1.num_batches_tracked', 'model.layer2.1.conv1.weight', 'model.layer2.1.bn1.weight', 'model.layer2.1.bn1.bias', 'model.layer2.1.bn1.running_mean', 'model.layer2.1.bn1.running_var', 'model.layer2.1.bn1.num_batches_tracked', 'model.layer2.1.conv2.weight', 'model.layer2.1.bn2.weight', 'model.layer2.1.bn2.bias', 'model.layer2.1.bn2.running_mean', 'model.layer2.1.bn2.running_var', 'model.layer2.1.bn2.num_batches_tracked', 'model.layer3.0.conv1.weight', 'model.layer3.0.bn1.weight', 'model.layer3.0.bn1.bias', 'model.layer3.0.bn1.running_mean', 'model.layer3.0.bn1.running_var', 'model.layer3.0.bn1.num_batches_tracked', 'model.layer3.0.conv2.weight', 'model.layer3.0.bn2.weight', 'model.layer3.0.bn2.bias', 'model.layer3.0.bn2.running_mean', 'model.layer3.0.bn2.running_var', 'model.layer3.0.bn2.num_batches_tracked', 'model.layer3.0.downsample.0.weight', 'model.layer3.0.downsample.1.weight', 'model.layer3.0.downsample.1.bias', 'model.layer3.0.downsample.1.running_mean', 'model.layer3.0.downsample.1.running_var', 'model.layer3.0.downsample.1.num_batches_tracked', 'model.layer3.1.conv1.weight', 'model.layer3.1.bn1.weight', 'model.layer3.1.bn1.bias', 'model.layer3.1.bn1.running_mean', 'model.layer3.1.bn1.running_var', 'model.layer3.1.bn1.num_batches_tracked', 'model.layer3.1.conv2.weight', 'model.layer3.1.bn2.weight', 'model.layer3.1.bn2.bias', 'model.layer3.1.bn2.running_mean', 'model.layer3.1.bn2.running_var', 'model.layer3.1.bn2.num_batches_tracked', 'model.layer4.0.conv1.weight', 'model.layer4.0.bn1.weight', 'model.layer4.0.bn1.bias', 'model.layer4.0.bn1.running_mean', 'model.layer4.0.bn1.running_var', 'model.layer4.0.bn1.num_batches_tracked', 'model.layer4.0.conv2.weight', 'model.layer4.0.bn2.weight', 'model.layer4.0.bn2.bias', 'model.layer4.0.bn2.running_mean', 'model.layer4.0.bn2.running_var', 'model.layer4.0.bn2.num_batches_tracked', 'model.layer4.0.downsample.0.weight', 'model.layer4.0.downsample.1.weight', 'model.layer4.0.downsample.1.bias', 'model.layer4.0.downsample.1.running_mean', 'model.layer4.0.downsample.1.running_var', 'model.layer4.0.downsample.1.num_batches_tracked', 'model.layer4.1.conv1.weight', 'model.layer4.1.bn1.weight', 'model.layer4.1.bn1.bias', 'model.layer4.1.bn1.running_mean', 'model.layer4.1.bn1.running_var', 'model.layer4.1.bn1.num_batches_tracked', 'model.layer4.1.conv2.weight', 'model.layer4.1.bn2.weight', 'model.layer4.1.bn2.bias', 'model.layer4.1.bn2.running_mean', 'model.layer4.1.bn2.running_var', 'model.layer4.1.bn2.num_batches_tracked', 'model.fc.weight', 'model.fc.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from image_modalities_classifier.models.modality_module import ModalityModule, EfficientNet, IResnet\n",
    "\n",
    "# ckp_resnet = \"/media/cumulus/curation_data/modality_classifiers/models/cord19/microscopy/resnet18_microscopy_2.pt\"\n",
    "ckp_resnet = \"/media/cumulus/curation_data/vil-al-interface/models/cord19/radiology/radiology_1.pt\"\n",
    "# ckp_resnet = '/home/jtt/Documents/resnet18_radiology_pickle_3.pt'\n",
    "ckp = str(artifacts / \"molecular/efficientnet-b1_molecular_6-epoch=7-val_loss=0.072.pt\")\n",
    "\n",
    "# model_pl = ModalityModule.load_from_checkpoint(ckp_resnet, strict=True)\n",
    "# print(type(model_pl))\n",
    "checkpoint = torch.load(ckp_resnet)\n",
    "print(checkpoint.keys())\n",
    "\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "\n",
    "\n",
    "# model = EfficientNet(name=\"efficientnet-b1\", num_classes=4)\n",
    "resnet_model = IResnet(name=\"resnet18\", num_classes=checkpoint[\"hyper_parameters\"][\"num_classes\"], pretrained=True, fine_tuned_from=\"whole\")\n",
    "\n",
    "print(checkpoint[\"state_dict\"].keys())\n",
    "state_dict = {}\n",
    "for key in checkpoint[\"state_dict\"].keys():\n",
    "    if key != 'loss.weight':\n",
    "      # new_key = f\"model.{key}\"\n",
    "      new_key = key\n",
    "      state_dict[new_key] = checkpoint[\"state_dict\"][key]\n",
    "\n",
    "# for key in checkpoint[\"state_dict\"].keys():    \n",
    "#     new_key = f\"model.{key}\"\n",
    "#     state_dict[new_key] = checkpoint[\"state_dict\"][key]\n",
    "\n",
    "# checkpoint[\"state_dict\"] = state_dict\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('/home/jtt/Documents/resnet18_radiology_pickle_3.pt', 'wb') as handle:\n",
    "#     pickle.dump(checkpoint, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "resnet_model.load_state_dict(state_dict)\n",
    "# resnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 62/62 [00:06<00:00,  8.92it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.99it/s]\n",
      "100%|██████████| 19/19 [00:03<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats\n",
      "{'f1_macro': tensor(0.8794), 'f1_micro': tensor(0.9306), 'f1_weighted': tensor(0.9268), 'accuracy': tensor(0.9306)}\n",
      "{'f1_macro': tensor(0.8539), 'f1_micro': tensor(0.9110), 'f1_weighted': tensor(0.9080), 'accuracy': tensor(0.9110)}\n",
      "{'f1_macro': tensor(0.8816), 'f1_micro': tensor(0.9288), 'f1_weighted': tensor(0.9265), 'accuracy': tensor(0.9288)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "base_img_path = \"/media/cumulus/curation_data/\"\n",
    "# all_data = data_path / \"cord19_radiology_v3.parquet\"\n",
    "all_data = \"/media/cumulus/curation_data/modality_classifiers/data/cord19/cord19_radiology_v1.parquet\"\n",
    "# efficient = str(artifacts / \"molecular/efficientnet-b1_molecular_3.pt\")\n",
    "# efficient = str(artifacts / \"molecular/efficientnet-b1_molecular_10-epoch=7-val_loss=0.072.pt\")\n",
    "efficient = str(artifacts / \"radiology/efficientnet-b0_radiology_3.pt\")\n",
    "# resnet = \"/media/cumulus/curation_data/modality_classifiers/models/cord19/microscopy/resnet18_microscopy_2.pt\"\n",
    "resnet = \"/media/cumulus/curation_data/vil-al-interface/models/cord19/radiology/radiology_1.pt\"\n",
    "# efficient = str(artifacts / \"molecular/last.pt\")\n",
    "\n",
    "# all_data = data_path / \"cord19_graphics_v4.parquet\"\n",
    "# efficient = str(artifacts / \"graphics/efficientnet-b1_graphics_4.pt\")\n",
    "\n",
    "df = pd.read_parquet(all_data)\n",
    "train_df = df.loc[df.split_set == 'TRAIN']\n",
    "val_df = df.loc[df.split_set=='VAL']\n",
    "test_df = df.loc[df.split_set=='TEST']\n",
    "\n",
    "config = RunConfig(32, cpu_count(), \"cuda:0\")\n",
    "predictor = SingleModalityPredictor(efficient, config)\n",
    "# predictor.model = resnet_model\n",
    "\n",
    "def test(data: pd.DataFrame, predictor: SingleModalityPredictor):\n",
    "    y_pred = predictor.predict(data, base_img_path)\n",
    "    y_true = data.label.values\n",
    "    encoded_y_pred = torch.Tensor(predictor.decoder.transform(y_pred))\n",
    "    encoded_y_true = torch.Tensor(predictor.decoder.transform(y_true))    \n",
    "    return calc_stats(encoded_y_true, encoded_y_pred, len(predictor.classes)), y_pred\n",
    "\n",
    "def calc_stats(y_true: torch.Tensor, y_pred: torch.Tensor, num_classes: int):\n",
    "    params = {\"task\": \"multiclass\", \"num_classes\": num_classes}\n",
    "\n",
    "    macro_params = {**params, \"average\": \"macro\"}\n",
    "    f1_macro_metric = F1Score(**macro_params)\n",
    "    micro_params = {**params, \"average\": \"micro\"}\n",
    "    f1_micro_metric = F1Score(**micro_params)\n",
    "    weighted_params = {**params, \"average\": \"weighted\"}\n",
    "    f1_wei_metric = F1Score(**weighted_params)\n",
    "    accuracy = Accuracy(**params)\n",
    "\n",
    "    return {\n",
    "        \"f1_macro\": f1_macro_metric(y_true, y_pred),\n",
    "        \"f1_micro\": f1_micro_metric(y_true, y_pred),\n",
    "        \"f1_weighted\": f1_wei_metric(y_true, y_pred),\n",
    "        \"accuracy\": accuracy(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "train_stats, _ = test(train_df, predictor)\n",
    "val_stats, _ = test(val_df, predictor)\n",
    "test_stats, y_test_pred = test(test_df, predictor)\n",
    "\n",
    "print(\"stats\")\n",
    "print(train_stats)\n",
    "print(val_stats)\n",
    "print(test_stats)\n",
    "\n",
    "\n",
    "# y_preds2_, y_probs2 = predictor.predict_with_probs(test_df, base_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gra.his' 'gra.sca' 'gra.oth' 'gra.lin' None]\n",
      "graphics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 92/1078 [00:16<02:58,  5.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m loader \u001b[39m=\u001b[39m load_dataloader(df_split, mean, std)\n\u001b[1;32m     74\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mfor\u001b[39;00m batch_imgs \u001b[39min\u001b[39;00m tqdm(loader):\n\u001b[1;32m     76\u001b[0m         data \u001b[39m=\u001b[39m batch_imgs\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m         batch_outputs \u001b[39m=\u001b[39m model(data)\n",
      "File \u001b[0;32m~/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/repos/bio-search/image-modalities-classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from numpy import hstack\n",
    "\n",
    "from image_modalities_classifier.dataset.image_dataset import EvalImageDataset\n",
    "from image_modalities_classifier.models.modality_module import ModalityModule, EfficientNet, IResnet\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from image_modalities_classifier.dataset.transforms import ModalityTransforms\n",
    "base_img_path = \"/media/cumulus/curation_data/\"\n",
    "\n",
    "classifiers = {\n",
    "    # \"higher-modality\":\"/media/cumulus/curation_data/vil-al-interface/models/cord19/higher-modality/higher-modality_1.pt\",\n",
    "    # \"experimental\":\"/media/cumulus/curation_data/vil-al-interface/models/cord19/experimental/experimental_1.pt\",    \n",
    "    \"graphics\":\"/media/cumulus/curation_data/vil-al-interface/models/cord19/graphics/graphics_1.pt\",\n",
    "    # \"microscopy\":\"/media/cumulus/curation_data/vil-al-interface/models/cord19/microscopy/microscopy_1.pt\",\n",
    "    # \"molecular\":\"/media/cumulus/curation_data/vil-al-interface/models/cord19/molecular/molecular_1.pt\",\n",
    "    # \"radiology\": \"/media/cumulus/curation_data/vil-al-interface/models/cord19/radiology/radiology_1.pt\",\n",
    "}\n",
    "\n",
    "classes = {\n",
    "    \"higher-modality\": [\"exp\",\"gra\",\"mic\",\"mol\",\"oth\",\"pho\",\"rad\"],\n",
    "    \"experimental\": [\"exp.gel\",\"exp.pla\"],    \n",
    "    \"graphics\": [\"gra.3dr\",\"gra.flow\",\"gra.his\",\"gra.lin\",\"gra.oth\",\"gra.sca\",\"gra.sig\"],\n",
    "    \"microscopy\": [\"mic.ele\",\"mic.flu\",\"mic.lig\"],\n",
    "    \"molecular\": [\"mol.3ds\", \"mol.che\", \"mol.dna\", \"mol.pro\"],\n",
    "    \"radiology\": [\"rad.ang\", \"rad.cmp\", \"rad.uls\", \"rad.xra\"],\n",
    "}\n",
    "\n",
    "data_path = Path(\"/media/cumulus/curation_data/vil-al-interface/files/cord19/\")\n",
    "\n",
    "def load_model(p):\n",
    "    checkpoint = torch.load(p)\n",
    "    resnet_model = IResnet(name=\"resnet18\", num_classes=checkpoint[\"hyper_parameters\"][\"num_classes\"], pretrained=True, fine_tuned_from=\"whole\")\n",
    "    state_dict = {}    \n",
    "    for key in checkpoint[\"state_dict\"].keys():\n",
    "        if key != 'loss.weight':\n",
    "            new_key = key\n",
    "            state_dict[new_key] = checkpoint[\"state_dict\"][key]\n",
    "    resnet_model.load_state_dict(state_dict)\n",
    "    return resnet_model, checkpoint[\"hyper_parameters\"][\"mean_dataset\"], checkpoint[\"hyper_parameters\"][\"std_dataset\"],checkpoint[\"hyper_parameters\"][\"num_classes\"]\n",
    "\n",
    "def load_dataloader(data, mean, std):\n",
    "    transforms_manager = ModalityTransforms(\"resnet18\", mean, std)\n",
    "    transforms = transforms_manager.test_transforms()\n",
    "    dataset = EvalImageDataset(data, base_img_path, transforms, path_col=\"img_path\")\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "for key in classifiers.keys():\n",
    "    filename = f\"cord19_{key}_v1.parquet\"\n",
    "    df = pd.read_parquet(data_path / filename)\n",
    "    print(df.label.unique())\n",
    "    model, mean, std, num_classes = load_model(classifiers[key])\n",
    "\n",
    "    decoder = LabelEncoder()\n",
    "    decoder.fit(classes[key])\n",
    "\n",
    "    print(key)\n",
    "    for split in [\"VAL\", \"TEST\"]:\n",
    "        predictions = []\n",
    "        df_split = df.loc[df.split_set==split]\n",
    "\n",
    "        model = model.eval().to(\"cuda:0\")\n",
    "        loader = load_dataloader(df_split, mean, std)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_imgs in tqdm(loader):\n",
    "                data = batch_imgs.to(\"cuda:0\")\n",
    "                batch_outputs = model(data)\n",
    "                batch_predictions = batch_outputs.argmax(dim=-1).cpu()\n",
    "                predictions.append(batch_predictions)\n",
    "            prediction_stack = hstack(predictions)\n",
    "\n",
    "        y_true = df_split.label.values\n",
    "        encoded_y_true = torch.Tensor(decoder.transform(y_true))\n",
    "\n",
    "        params = {\"task\": \"multiclass\", \"num_classes\": num_classes}\n",
    "        macro_params = {**params, \"average\": \"macro\"}\n",
    "        f1_macro_metric = F1Score(**macro_params)\n",
    "        micro_params = {**params, \"average\": \"micro\"}\n",
    "        f1_micro_metric = F1Score(**micro_params)\n",
    "        weighted_params = {**params, \"average\": \"weighted\"}\n",
    "        f1_wei_metric = F1Score(**weighted_params)\n",
    "        accuracy = Accuracy(**params)\n",
    "\n",
    "        y_true = torch.Tensor(encoded_y_true)\n",
    "        prediction_stack = torch.Tensor(prediction_stack)\n",
    "        f1_macro=f1_macro_metric(y_true, prediction_stack)\n",
    "        f1_micro=f1_micro_metric(y_true, prediction_stack)\n",
    "        f1_weighted=f1_wei_metric(y_true, prediction_stack)\n",
    "        acc=accuracy(y_true, prediction_stack)\n",
    "        print(f\"{split}, {f1_macro}, {f1_micro}, {f1_weighted}, {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro tensor(0.9200)\n",
      "f1_micro tensor(0.9508)\n",
      "f1_weighted tensor(0.9499)\n",
      "accuracy tensor(0.9508)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.features.0.0.weight\n",
      "model.features.0.1.weight\n",
      "model.features.0.1.bias\n",
      "model.features.1.0.block.0.0.weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 2.0166e-02, -1.0751e-01, -5.8210e-03],\n",
      "          [-1.2274e-01,  3.2433e-01, -8.6749e-02],\n",
      "          [-7.4220e-02,  5.3751e-01,  6.5358e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6051e-01, -1.0697e-01, -5.1722e-02],\n",
      "          [ 1.1956e+00, -4.7957e-01, -4.1340e-02],\n",
      "          [-2.0706e-01, -1.6970e-01, -6.0464e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2519e-01, -3.8404e-01, -2.5227e-01],\n",
      "          [-1.0502e-01,  1.3681e+00,  1.4668e-01],\n",
      "          [-1.0174e-01, -1.5479e-03, -8.9848e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4568e-02, -5.4957e-01,  8.6564e-02],\n",
      "          [-3.7460e-01,  2.3233e+00, -4.7775e-01],\n",
      "          [-8.9641e-02, -1.4202e-01, -3.2014e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5220e-02, -2.6700e-01,  3.9462e-02],\n",
      "          [-1.1228e-01,  9.0248e-01, -1.5974e-01],\n",
      "          [-9.0730e-02,  1.6116e-01, -1.5105e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9589e-02,  1.8996e-01,  2.0447e-02],\n",
      "          [ 2.0564e-01, -1.7336e+00,  1.8490e-01],\n",
      "          [ 3.8766e-02,  1.7465e-02,  9.0169e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1473e-02,  1.9737e-01, -3.5433e-02],\n",
      "          [ 9.4513e-03, -1.9348e+00,  1.3105e-01],\n",
      "          [ 1.6782e-02,  1.5504e-01, -2.5803e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8800e-02, -1.0464e-02,  1.0446e-01],\n",
      "          [-1.3485e+00, -8.3316e-01,  1.2560e+00],\n",
      "          [ 1.3955e-01, -8.0858e-02,  1.1319e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2089e-02,  2.2201e-02, -8.4542e-02],\n",
      "          [ 5.8316e-02,  7.1647e-01, -6.2444e-02],\n",
      "          [ 6.5305e-03,  6.3767e-02, -8.9859e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2411e-02, -1.4149e-01, -3.5460e-02],\n",
      "          [-2.2803e-02,  9.9773e-01, -2.3961e-02],\n",
      "          [-7.8518e-02,  1.3315e-01, -3.1770e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.0952e-02,  2.9731e-02,  5.1874e-03],\n",
      "          [-1.7867e-01,  7.1342e-01,  1.1981e-01],\n",
      "          [-9.4210e-02,  2.4768e-02, -6.3151e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1978e-01,  5.7443e-01, -7.3749e-02],\n",
      "          [ 9.8836e-02, -2.0660e+00,  3.6425e-01],\n",
      "          [ 3.4076e-01, -8.2696e-02,  1.5875e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3614e-02,  8.9440e-02,  4.7231e-02],\n",
      "          [ 4.3351e-02, -2.9044e-01, -7.5155e-02],\n",
      "          [ 2.4808e-01, -3.5315e-01, -2.6360e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3414e-01, -1.3897e-01,  4.8180e-02],\n",
      "          [-2.7435e-01,  7.7541e-01, -1.1831e-01],\n",
      "          [-6.5741e-02,  1.5052e-01,  6.4008e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5910e-01, -2.0337e+00, -6.2712e-02],\n",
      "          [ 2.1690e-02, -3.7008e-02,  1.2509e-02],\n",
      "          [-1.6625e-02,  2.5512e-02,  1.7070e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5118e-01, -2.3142e-01, -2.5905e-02],\n",
      "          [ 1.4625e+00,  4.2183e-01, -3.2185e-03],\n",
      "          [-2.3696e-01, -1.4516e-01, -2.9130e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0353e-01,  5.5777e-01, -1.0967e-01],\n",
      "          [ 1.5947e-01, -2.0287e+00,  4.3731e-01],\n",
      "          [ 3.4664e-01, -7.8549e-02,  9.6516e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1404e-02, -1.5111e+00,  1.1725e-01],\n",
      "          [ 1.4778e-01, -8.6531e-01,  4.2243e-02],\n",
      "          [ 4.8506e-02,  1.5917e-02, -3.6574e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0402e-02,  1.0997e-01,  6.0120e-02],\n",
      "          [-1.8139e-02, -7.7742e-01,  6.0948e-02],\n",
      "          [ 1.3419e-01, -9.1603e-02,  1.3275e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0780e-02,  6.3259e-01, -3.0793e-02],\n",
      "          [ 3.9768e-01, -2.4876e+00,  8.8835e-02],\n",
      "          [ 5.5606e-03,  9.6308e-02, -9.6148e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8544e-02,  9.0703e-03,  1.2163e-01],\n",
      "          [ 4.1440e-01,  2.1834e-01, -7.3238e-01],\n",
      "          [ 1.4349e-01,  1.0184e-01, -2.9244e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1044e-03,  3.4462e+00,  1.6240e-01],\n",
      "          [-3.6735e-01, -2.7899e+00, -4.6721e-01],\n",
      "          [ 3.2221e-01, -5.9028e-01,  2.9857e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4911e-02,  1.9492e-01,  2.6038e-02],\n",
      "          [-1.8189e-03, -6.6556e-01,  1.5941e-01],\n",
      "          [ 1.0157e-01, -2.0388e-01,  9.0328e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6141e-01,  3.0489e+00, -3.3651e-01],\n",
      "          [-8.9162e-01, -2.3900e+00,  4.4385e-02],\n",
      "          [ 2.6247e-01, -5.1839e-01,  1.7665e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0592e-02, -2.3053e-02,  2.7351e-02],\n",
      "          [-1.5757e+00, -4.7868e-01, -7.5064e-02],\n",
      "          [-1.6782e-02,  1.4076e-02,  3.0773e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8986e-02, -2.3195e-02,  5.0365e-02],\n",
      "          [ 6.6743e-02, -7.2043e-01,  1.9499e-01],\n",
      "          [ 9.0382e-02, -1.1299e-01,  9.2537e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0256e-01, -9.9523e-01,  2.6428e-01],\n",
      "          [ 2.5577e+00, -1.5337e+00, -8.6017e-01],\n",
      "          [ 4.5890e-01, -8.8221e-01,  2.3366e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.4860e-02, -4.5127e-01, -1.8252e-01],\n",
      "          [ 1.4253e-01,  1.6494e+00, -3.3844e-01],\n",
      "          [-7.3971e-02, -3.6463e-01, -1.6553e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1728e-01,  1.7733e-01,  1.4878e-01],\n",
      "          [ 1.5325e-01, -1.7346e+00,  1.7411e-01],\n",
      "          [ 6.6004e-02,  9.0396e-02,  6.4085e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3498e-01,  1.8848e-01,  8.6771e-02],\n",
      "          [ 1.1096e-01, -1.3522e+00,  2.6166e-01],\n",
      "          [ 1.4605e-01,  5.7945e-02,  8.2853e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2989e-02, -4.5134e-01,  5.7990e-02],\n",
      "          [-3.7714e-01,  1.8514e+00, -3.7755e-01],\n",
      "          [-1.2808e-01,  6.8343e-02, -1.1202e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.3558e-02,  2.6087e-01, -7.0557e-03],\n",
      "          [ 5.9154e-03, -1.1534e+00,  1.4472e-02],\n",
      "          [ 1.4988e-01, -3.0025e-01,  2.1354e-01]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "model.features.1.0.block.0.1.weight\n",
      "model.features.1.0.block.0.1.bias\n",
      "model.features.1.0.block.1.fc1.weight\n",
      "model.features.1.0.block.1.fc1.bias\n",
      "model.features.1.0.block.1.fc2.weight\n",
      "model.features.1.0.block.1.fc2.bias\n",
      "model.features.1.0.block.2.0.weight\n",
      "model.features.1.0.block.2.1.weight\n",
      "model.features.1.0.block.2.1.bias\n",
      "model.features.1.1.block.0.0.weight\n",
      "model.features.1.1.block.0.1.weight\n",
      "model.features.1.1.block.0.1.bias\n",
      "model.features.1.1.block.1.fc1.weight\n",
      "model.features.1.1.block.1.fc1.bias\n",
      "model.features.1.1.block.1.fc2.weight\n",
      "model.features.1.1.block.1.fc2.bias\n",
      "model.features.1.1.block.2.0.weight\n",
      "model.features.1.1.block.2.1.weight\n",
      "model.features.1.1.block.2.1.bias\n",
      "model.features.2.0.block.0.0.weight\n",
      "model.features.2.0.block.0.1.weight\n",
      "model.features.2.0.block.0.1.bias\n",
      "model.features.2.0.block.1.0.weight\n",
      "model.features.2.0.block.1.1.weight\n",
      "model.features.2.0.block.1.1.bias\n",
      "model.features.2.0.block.2.fc1.weight\n",
      "model.features.2.0.block.2.fc1.bias\n",
      "model.features.2.0.block.2.fc2.weight\n",
      "model.features.2.0.block.2.fc2.bias\n",
      "model.features.2.0.block.3.0.weight\n",
      "model.features.2.0.block.3.1.weight\n",
      "model.features.2.0.block.3.1.bias\n",
      "model.features.2.1.block.0.0.weight\n",
      "model.features.2.1.block.0.1.weight\n",
      "model.features.2.1.block.0.1.bias\n",
      "model.features.2.1.block.1.0.weight\n",
      "model.features.2.1.block.1.1.weight\n",
      "model.features.2.1.block.1.1.bias\n",
      "model.features.2.1.block.2.fc1.weight\n",
      "model.features.2.1.block.2.fc1.bias\n",
      "model.features.2.1.block.2.fc2.weight\n",
      "model.features.2.1.block.2.fc2.bias\n",
      "model.features.2.1.block.3.0.weight\n",
      "model.features.2.1.block.3.1.weight\n",
      "model.features.2.1.block.3.1.bias\n",
      "model.features.2.2.block.0.0.weight\n",
      "model.features.2.2.block.0.1.weight\n",
      "model.features.2.2.block.0.1.bias\n",
      "model.features.2.2.block.1.0.weight\n",
      "model.features.2.2.block.1.1.weight\n",
      "model.features.2.2.block.1.1.bias\n",
      "model.features.2.2.block.2.fc1.weight\n",
      "model.features.2.2.block.2.fc1.bias\n",
      "model.features.2.2.block.2.fc2.weight\n",
      "model.features.2.2.block.2.fc2.bias\n",
      "model.features.2.2.block.3.0.weight\n",
      "model.features.2.2.block.3.1.weight\n",
      "model.features.2.2.block.3.1.bias\n",
      "model.features.3.0.block.0.0.weight\n",
      "model.features.3.0.block.0.1.weight\n",
      "model.features.3.0.block.0.1.bias\n",
      "model.features.3.0.block.1.0.weight\n",
      "model.features.3.0.block.1.1.weight\n",
      "model.features.3.0.block.1.1.bias\n",
      "model.features.3.0.block.2.fc1.weight\n",
      "model.features.3.0.block.2.fc1.bias\n",
      "model.features.3.0.block.2.fc2.weight\n",
      "model.features.3.0.block.2.fc2.bias\n",
      "model.features.3.0.block.3.0.weight\n",
      "model.features.3.0.block.3.1.weight\n",
      "model.features.3.0.block.3.1.bias\n",
      "model.features.3.1.block.0.0.weight\n",
      "model.features.3.1.block.0.1.weight\n",
      "model.features.3.1.block.0.1.bias\n",
      "model.features.3.1.block.1.0.weight\n",
      "model.features.3.1.block.1.1.weight\n",
      "model.features.3.1.block.1.1.bias\n",
      "model.features.3.1.block.2.fc1.weight\n",
      "model.features.3.1.block.2.fc1.bias\n",
      "model.features.3.1.block.2.fc2.weight\n",
      "model.features.3.1.block.2.fc2.bias\n",
      "model.features.3.1.block.3.0.weight\n",
      "model.features.3.1.block.3.1.weight\n",
      "model.features.3.1.block.3.1.bias\n",
      "model.features.3.2.block.0.0.weight\n",
      "model.features.3.2.block.0.1.weight\n",
      "model.features.3.2.block.0.1.bias\n",
      "model.features.3.2.block.1.0.weight\n",
      "model.features.3.2.block.1.1.weight\n",
      "model.features.3.2.block.1.1.bias\n",
      "model.features.3.2.block.2.fc1.weight\n",
      "model.features.3.2.block.2.fc1.bias\n",
      "model.features.3.2.block.2.fc2.weight\n",
      "model.features.3.2.block.2.fc2.bias\n",
      "model.features.3.2.block.3.0.weight\n",
      "model.features.3.2.block.3.1.weight\n",
      "model.features.3.2.block.3.1.bias\n",
      "model.features.4.0.block.0.0.weight\n",
      "model.features.4.0.block.0.1.weight\n",
      "model.features.4.0.block.0.1.bias\n",
      "model.features.4.0.block.1.0.weight\n",
      "model.features.4.0.block.1.1.weight\n",
      "model.features.4.0.block.1.1.bias\n",
      "model.features.4.0.block.2.fc1.weight\n",
      "model.features.4.0.block.2.fc1.bias\n",
      "model.features.4.0.block.2.fc2.weight\n",
      "model.features.4.0.block.2.fc2.bias\n",
      "model.features.4.0.block.3.0.weight\n",
      "model.features.4.0.block.3.1.weight\n",
      "model.features.4.0.block.3.1.bias\n",
      "model.features.4.1.block.0.0.weight\n",
      "model.features.4.1.block.0.1.weight\n",
      "model.features.4.1.block.0.1.bias\n",
      "model.features.4.1.block.1.0.weight\n",
      "model.features.4.1.block.1.1.weight\n",
      "model.features.4.1.block.1.1.bias\n",
      "model.features.4.1.block.2.fc1.weight\n",
      "model.features.4.1.block.2.fc1.bias\n",
      "model.features.4.1.block.2.fc2.weight\n",
      "model.features.4.1.block.2.fc2.bias\n",
      "model.features.4.1.block.3.0.weight\n",
      "model.features.4.1.block.3.1.weight\n",
      "model.features.4.1.block.3.1.bias\n",
      "model.features.4.2.block.0.0.weight\n",
      "model.features.4.2.block.0.1.weight\n",
      "model.features.4.2.block.0.1.bias\n",
      "model.features.4.2.block.1.0.weight\n",
      "model.features.4.2.block.1.1.weight\n",
      "model.features.4.2.block.1.1.bias\n",
      "model.features.4.2.block.2.fc1.weight\n",
      "model.features.4.2.block.2.fc1.bias\n",
      "model.features.4.2.block.2.fc2.weight\n",
      "model.features.4.2.block.2.fc2.bias\n",
      "model.features.4.2.block.3.0.weight\n",
      "model.features.4.2.block.3.1.weight\n",
      "model.features.4.2.block.3.1.bias\n",
      "model.features.4.3.block.0.0.weight\n",
      "model.features.4.3.block.0.1.weight\n",
      "model.features.4.3.block.0.1.bias\n",
      "model.features.4.3.block.1.0.weight\n",
      "model.features.4.3.block.1.1.weight\n",
      "model.features.4.3.block.1.1.bias\n",
      "model.features.4.3.block.2.fc1.weight\n",
      "model.features.4.3.block.2.fc1.bias\n",
      "model.features.4.3.block.2.fc2.weight\n",
      "model.features.4.3.block.2.fc2.bias\n",
      "model.features.4.3.block.3.0.weight\n",
      "model.features.4.3.block.3.1.weight\n",
      "model.features.4.3.block.3.1.bias\n",
      "model.features.5.0.block.0.0.weight\n",
      "model.features.5.0.block.0.1.weight\n",
      "model.features.5.0.block.0.1.bias\n",
      "model.features.5.0.block.1.0.weight\n",
      "model.features.5.0.block.1.1.weight\n",
      "model.features.5.0.block.1.1.bias\n",
      "model.features.5.0.block.2.fc1.weight\n",
      "model.features.5.0.block.2.fc1.bias\n",
      "model.features.5.0.block.2.fc2.weight\n",
      "model.features.5.0.block.2.fc2.bias\n",
      "model.features.5.0.block.3.0.weight\n",
      "model.features.5.0.block.3.1.weight\n",
      "model.features.5.0.block.3.1.bias\n",
      "model.features.5.1.block.0.0.weight\n",
      "model.features.5.1.block.0.1.weight\n",
      "model.features.5.1.block.0.1.bias\n",
      "model.features.5.1.block.1.0.weight\n",
      "model.features.5.1.block.1.1.weight\n",
      "model.features.5.1.block.1.1.bias\n",
      "model.features.5.1.block.2.fc1.weight\n",
      "model.features.5.1.block.2.fc1.bias\n",
      "model.features.5.1.block.2.fc2.weight\n",
      "model.features.5.1.block.2.fc2.bias\n",
      "model.features.5.1.block.3.0.weight\n",
      "model.features.5.1.block.3.1.weight\n",
      "model.features.5.1.block.3.1.bias\n",
      "model.features.5.2.block.0.0.weight\n",
      "model.features.5.2.block.0.1.weight\n",
      "model.features.5.2.block.0.1.bias\n",
      "model.features.5.2.block.1.0.weight\n",
      "model.features.5.2.block.1.1.weight\n",
      "model.features.5.2.block.1.1.bias\n",
      "model.features.5.2.block.2.fc1.weight\n",
      "model.features.5.2.block.2.fc1.bias\n",
      "model.features.5.2.block.2.fc2.weight\n",
      "model.features.5.2.block.2.fc2.bias\n",
      "model.features.5.2.block.3.0.weight\n",
      "model.features.5.2.block.3.1.weight\n",
      "model.features.5.2.block.3.1.bias\n",
      "model.features.5.3.block.0.0.weight\n",
      "model.features.5.3.block.0.1.weight\n",
      "model.features.5.3.block.0.1.bias\n",
      "model.features.5.3.block.1.0.weight\n",
      "model.features.5.3.block.1.1.weight\n",
      "model.features.5.3.block.1.1.bias\n",
      "model.features.5.3.block.2.fc1.weight\n",
      "model.features.5.3.block.2.fc1.bias\n",
      "model.features.5.3.block.2.fc2.weight\n",
      "model.features.5.3.block.2.fc2.bias\n",
      "model.features.5.3.block.3.0.weight\n",
      "model.features.5.3.block.3.1.weight\n",
      "model.features.5.3.block.3.1.bias\n",
      "model.features.6.0.block.0.0.weight\n",
      "model.features.6.0.block.0.1.weight\n",
      "model.features.6.0.block.0.1.bias\n",
      "model.features.6.0.block.1.0.weight\n",
      "model.features.6.0.block.1.1.weight\n",
      "model.features.6.0.block.1.1.bias\n",
      "model.features.6.0.block.2.fc1.weight\n",
      "model.features.6.0.block.2.fc1.bias\n",
      "model.features.6.0.block.2.fc2.weight\n",
      "model.features.6.0.block.2.fc2.bias\n",
      "model.features.6.0.block.3.0.weight\n",
      "model.features.6.0.block.3.1.weight\n",
      "model.features.6.0.block.3.1.bias\n",
      "model.features.6.1.block.0.0.weight\n",
      "model.features.6.1.block.0.1.weight\n",
      "model.features.6.1.block.0.1.bias\n",
      "model.features.6.1.block.1.0.weight\n",
      "model.features.6.1.block.1.1.weight\n",
      "model.features.6.1.block.1.1.bias\n",
      "model.features.6.1.block.2.fc1.weight\n",
      "model.features.6.1.block.2.fc1.bias\n",
      "model.features.6.1.block.2.fc2.weight\n",
      "model.features.6.1.block.2.fc2.bias\n",
      "model.features.6.1.block.3.0.weight\n",
      "model.features.6.1.block.3.1.weight\n",
      "model.features.6.1.block.3.1.bias\n",
      "model.features.6.2.block.0.0.weight\n",
      "model.features.6.2.block.0.1.weight\n",
      "model.features.6.2.block.0.1.bias\n",
      "model.features.6.2.block.1.0.weight\n",
      "model.features.6.2.block.1.1.weight\n",
      "model.features.6.2.block.1.1.bias\n",
      "model.features.6.2.block.2.fc1.weight\n",
      "model.features.6.2.block.2.fc1.bias\n",
      "model.features.6.2.block.2.fc2.weight\n",
      "model.features.6.2.block.2.fc2.bias\n",
      "model.features.6.2.block.3.0.weight\n",
      "model.features.6.2.block.3.1.weight\n",
      "model.features.6.2.block.3.1.bias\n",
      "model.features.6.3.block.0.0.weight\n",
      "model.features.6.3.block.0.1.weight\n",
      "model.features.6.3.block.0.1.bias\n",
      "model.features.6.3.block.1.0.weight\n",
      "model.features.6.3.block.1.1.weight\n",
      "model.features.6.3.block.1.1.bias\n",
      "model.features.6.3.block.2.fc1.weight\n",
      "model.features.6.3.block.2.fc1.bias\n",
      "model.features.6.3.block.2.fc2.weight\n",
      "model.features.6.3.block.2.fc2.bias\n",
      "model.features.6.3.block.3.0.weight\n",
      "model.features.6.3.block.3.1.weight\n",
      "model.features.6.3.block.3.1.bias\n",
      "model.features.6.4.block.0.0.weight\n",
      "model.features.6.4.block.0.1.weight\n",
      "model.features.6.4.block.0.1.bias\n",
      "model.features.6.4.block.1.0.weight\n",
      "model.features.6.4.block.1.1.weight\n",
      "model.features.6.4.block.1.1.bias\n",
      "model.features.6.4.block.2.fc1.weight\n",
      "model.features.6.4.block.2.fc1.bias\n",
      "model.features.6.4.block.2.fc2.weight\n",
      "model.features.6.4.block.2.fc2.bias\n",
      "model.features.6.4.block.3.0.weight\n",
      "model.features.6.4.block.3.1.weight\n",
      "model.features.6.4.block.3.1.bias\n",
      "model.features.7.0.block.0.0.weight\n",
      "model.features.7.0.block.0.1.weight\n",
      "model.features.7.0.block.0.1.bias\n",
      "model.features.7.0.block.1.0.weight\n",
      "model.features.7.0.block.1.1.weight\n",
      "model.features.7.0.block.1.1.bias\n",
      "model.features.7.0.block.2.fc1.weight\n",
      "model.features.7.0.block.2.fc1.bias\n",
      "model.features.7.0.block.2.fc2.weight\n",
      "model.features.7.0.block.2.fc2.bias\n",
      "model.features.7.0.block.3.0.weight\n",
      "model.features.7.0.block.3.1.weight\n",
      "model.features.7.0.block.3.1.bias\n",
      "model.features.7.1.block.0.0.weight\n",
      "model.features.7.1.block.0.1.weight\n",
      "model.features.7.1.block.0.1.bias\n",
      "model.features.7.1.block.1.0.weight\n",
      "model.features.7.1.block.1.1.weight\n",
      "model.features.7.1.block.1.1.bias\n",
      "model.features.7.1.block.2.fc1.weight\n",
      "model.features.7.1.block.2.fc1.bias\n",
      "model.features.7.1.block.2.fc2.weight\n",
      "model.features.7.1.block.2.fc2.bias\n",
      "model.features.7.1.block.3.0.weight\n",
      "model.features.7.1.block.3.1.weight\n",
      "model.features.7.1.block.3.1.bias\n",
      "model.features.8.0.weight\n",
      "model.features.8.1.weight\n",
      "model.features.8.1.bias\n",
      "model.classifier.1.weight\n",
      "model.classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in predictor.model.named_parameters():\n",
    "    print(name)\n",
    "    if name == \"model.features.1.0.block.0.0.weight\":\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4168663/3238558131.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"pred\"] = y_test_pred\n"
     ]
    }
   ],
   "source": [
    "test_df[\"pred\"] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>img_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>caption</th>\n",
       "      <th>original</th>\n",
       "      <th>split_set</th>\n",
       "      <th>is_gt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>5e5f2dc6de000f09242e44b7</td>\n",
       "      <td>tinman/p10209262/10209262/4_1/005.jpg</td>\n",
       "      <td>545.00000000000000</td>\n",
       "      <td>253.00000000000000</td>\n",
       "      <td>mol.pro</td>\n",
       "      <td>tinman</td>\n",
       "      <td>Fig. 1A.</td>\n",
       "      <td>mol.pro</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>mol.pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1423-0127-17-13-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/GCHE/1423-...</td>\n",
       "      <td>600.00000000000000</td>\n",
       "      <td>268.00000000000000</td>\n",
       "      <td>mol.che</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Chemical structure of BPR1P0034 .,</td>\n",
       "      <td>GCHE</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>mol.che</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1471-2148-9-206-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/GCHE/1471-...</td>\n",
       "      <td>600.00000000000000</td>\n",
       "      <td>375.00000000000000</td>\n",
       "      <td>mol.che</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Simplified GA biosynthetic pathway in plants ....</td>\n",
       "      <td>GCHE</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>mol.dna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1471-2164-8-95-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/GCHE/1471-...</td>\n",
       "      <td>600.00000000000000</td>\n",
       "      <td>360.00000000000000</td>\n",
       "      <td>mol.che</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Chemical structure of citrinin.,</td>\n",
       "      <td>GCHE</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>mol.che</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1471-2199-6-16-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/GGEN/1471-...</td>\n",
       "      <td>600.00000000000000</td>\n",
       "      <td>597.00000000000000</td>\n",
       "      <td>mol.dna</td>\n",
       "      <td>clef13</td>\n",
       "      <td>The zinc-finger (ZF) domain is highly conserve...</td>\n",
       "      <td>GGEN</td>\n",
       "      <td>TEST</td>\n",
       "      <td>True</td>\n",
       "      <td>mol.dna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           img  \\\n",
       "247   5e5f2dc6de000f09242e44b7   \n",
       "1086     1423-0127-17-13-1.jpg   \n",
       "1087     1471-2148-9-206-1.jpg   \n",
       "1088      1471-2164-8-95-1.jpg   \n",
       "1089      1471-2199-6-16-1.jpg   \n",
       "\n",
       "                                               img_path               width  \\\n",
       "247               tinman/p10209262/10209262/4_1/005.jpg  545.00000000000000   \n",
       "1086  subfigure-classification/2013/train/GCHE/1423-...  600.00000000000000   \n",
       "1087  subfigure-classification/2013/train/GCHE/1471-...  600.00000000000000   \n",
       "1088  subfigure-classification/2013/train/GCHE/1471-...  600.00000000000000   \n",
       "1089  subfigure-classification/2013/train/GGEN/1471-...  600.00000000000000   \n",
       "\n",
       "                  height    label  source  \\\n",
       "247   253.00000000000000  mol.pro  tinman   \n",
       "1086  268.00000000000000  mol.che  clef13   \n",
       "1087  375.00000000000000  mol.che  clef13   \n",
       "1088  360.00000000000000  mol.che  clef13   \n",
       "1089  597.00000000000000  mol.dna  clef13   \n",
       "\n",
       "                                                caption original split_set  \\\n",
       "247                                            Fig. 1A.  mol.pro      TEST   \n",
       "1086                 Chemical structure of BPR1P0034 .,     GCHE      TEST   \n",
       "1087  Simplified GA biosynthetic pathway in plants ....     GCHE      TEST   \n",
       "1088                   Chemical structure of citrinin.,     GCHE      TEST   \n",
       "1089  The zinc-finger (ZF) domain is highly conserve...     GGEN      TEST   \n",
       "\n",
       "      is_gt     pred  \n",
       "247    True  mol.pro  \n",
       "1086   True  mol.che  \n",
       "1087   True  mol.dna  \n",
       "1088   True  mol.che  \n",
       "1089   True  mol.dna  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mol.3ds', 'mol.che', 'mol.dna', 'mol.pro'], dtype='<U7')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]\n",
    "predictor.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 2., 2., 2.])\n",
      "tensor([0., 0., 0.,  ..., 2., 2., 2.])\n",
      "tensor(0.8723)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import F1Score, Precision, Recall\n",
    "import torch\n",
    "\n",
    "num_classes = len(predictor.classes)\n",
    "params = {\"task\": \"multiclass\", \"num_classes\": num_classes}\n",
    "\n",
    "macro_params = {**params, \"average\": \"macro\"}\n",
    "f1_metric = F1Score(**macro_params)\n",
    "\n",
    "encoded_y_pred = torch.Tensor(predictor.decoder.transform(predictions))\n",
    "encoded_y_true = torch.Tensor(predictor.decoder.transform(train_df.label.values))\n",
    "\n",
    "f1 = f1_metric(encoded_y_pred, encoded_y_true)\n",
    "print(encoded_y_pred)\n",
    "print(encoded_y_true)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87230271411849"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = train_df.label.values\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1_score(ground_truth, predictions, average=\"macro\")\n",
    "f1_score(ground_truth, predictions, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rad.cmp', 'rad.cmp', 'rad.cmp', ..., 'rad.xra', 'rad.xra',\n",
       "       'rad.xra'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rad.xra', 'rad.xra', 'rad.xra', ..., 'rad.xra', 'rad.xra',\n",
       "       'rad.cmp'], dtype='<U7')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>img_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_gt</th>\n",
       "      <th>original</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1471-2121-3-29-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of a S2 cell transfect...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.004090134, -0.1427809, -0.1732117, -0.1795...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1471-2172-7-1-4.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Distribution of Bu-1 +  cells . PALT is seen b...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.7017001, -0.077621244, -0.13674453, -0.0627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1471-2180-10-283-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Merged image of the phase contrast and fluores...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.11191165, -0.17719942, -0.15846144, -0.137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1471-2180-5-17-9.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>552.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>An epifluorescence image of  Thermus aquaticus .,</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[1.7194173, -0.08525187, -0.12554392, -0.05411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1471-2199-11-11-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of tagged-NrdB cells ....</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.18778822, -0.09744128, -0.14088048, -0.1344...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img                                           img_path  \\\n",
       "0    1471-2121-3-29-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "1     1471-2172-7-1-4.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "2  1471-2180-10-283-1.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "3    1471-2180-5-17-9.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "4   1471-2199-11-11-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "\n",
       "   width  height    label  source  \\\n",
       "0  600.0   541.0  mic.flu  clef13   \n",
       "1  600.0   600.0  mic.flu  clef13   \n",
       "2  600.0   444.0  mic.flu  clef13   \n",
       "3  552.0   548.0  mic.flu  clef13   \n",
       "4  600.0   576.0  mic.flu  clef13   \n",
       "\n",
       "                                             caption  is_gt original  \\\n",
       "0  Fluorescence microscopy of a S2 cell transfect...   True     DMFL   \n",
       "1  Distribution of Bu-1 +  cells . PALT is seen b...   True     DMFL   \n",
       "2  Merged image of the phase contrast and fluores...   True     DMFL   \n",
       "3  An epifluorescence image of  Thermus aquaticus .,   True     DMFL   \n",
       "4  Fluorescence microscopy of tagged-NrdB cells ....   True     DMFL   \n",
       "\n",
       "  split_set                                           features  \n",
       "0     TRAIN  [-0.004090134, -0.1427809, -0.1732117, -0.1795...  \n",
       "1     TRAIN  [0.7017001, -0.077621244, -0.13674453, -0.0627...  \n",
       "2     TRAIN  [-0.11191165, -0.17719942, -0.15846144, -0.137...  \n",
       "3     TRAIN  [1.7194173, -0.08525187, -0.12554392, -0.05411...  \n",
       "4     TRAIN  [0.18778822, -0.09744128, -0.14088048, -0.1344...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"features\"] = list(features)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/image-modalities-classifier/.venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/image-modalities-classifier/.venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# restart because the feature extractor is affecting the original model\n",
    "predictor = SingleModalityPredictor(str(artifacts / \"microscopy/efficientnet-b0_microscopy_0.pt\"), config)\n",
    "predictions, probabilities = predictor.predict_with_probs(df, base_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>img_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_gt</th>\n",
       "      <th>original</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1471-2121-3-29-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of a S2 cell transfect...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.004090134, -0.1427809, -0.1732117, -0.1795...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.001480210805311799, 0.9981943964958191, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1471-2172-7-1-4.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Distribution of Bu-1 +  cells . PALT is seen b...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.7017001, -0.077621244, -0.13674453, -0.0627...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[2.457024311297573e-05, 0.999975323677063, 5.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1471-2180-10-283-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Merged image of the phase contrast and fluores...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.11191165, -0.17719942, -0.15846144, -0.137...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.08060691505670547, 0.873210072517395, 0.046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1471-2180-5-17-9.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>552.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>An epifluorescence image of  Thermus aquaticus .,</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[1.7194173, -0.08525187, -0.12554392, -0.05411...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[2.004333810035064e-09, 1.0, 6.101986537582205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1471-2199-11-11-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of tagged-NrdB cells ....</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.18778822, -0.09744128, -0.14088048, -0.1344...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.013884089887142181, 0.9833231568336487, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img                                           img_path  \\\n",
       "0    1471-2121-3-29-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "1     1471-2172-7-1-4.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "2  1471-2180-10-283-1.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "3    1471-2180-5-17-9.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "4   1471-2199-11-11-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "\n",
       "   width  height    label  source  \\\n",
       "0  600.0   541.0  mic.flu  clef13   \n",
       "1  600.0   600.0  mic.flu  clef13   \n",
       "2  600.0   444.0  mic.flu  clef13   \n",
       "3  552.0   548.0  mic.flu  clef13   \n",
       "4  600.0   576.0  mic.flu  clef13   \n",
       "\n",
       "                                             caption  is_gt original  \\\n",
       "0  Fluorescence microscopy of a S2 cell transfect...   True     DMFL   \n",
       "1  Distribution of Bu-1 +  cells . PALT is seen b...   True     DMFL   \n",
       "2  Merged image of the phase contrast and fluores...   True     DMFL   \n",
       "3  An epifluorescence image of  Thermus aquaticus .,   True     DMFL   \n",
       "4  Fluorescence microscopy of tagged-NrdB cells ....   True     DMFL   \n",
       "\n",
       "  split_set                                           features prediction  \\\n",
       "0     TRAIN  [-0.004090134, -0.1427809, -0.1732117, -0.1795...    mic.flu   \n",
       "1     TRAIN  [0.7017001, -0.077621244, -0.13674453, -0.0627...    mic.flu   \n",
       "2     TRAIN  [-0.11191165, -0.17719942, -0.15846144, -0.137...    mic.flu   \n",
       "3     TRAIN  [1.7194173, -0.08525187, -0.12554392, -0.05411...    mic.flu   \n",
       "4     TRAIN  [0.18778822, -0.09744128, -0.14088048, -0.1344...    mic.flu   \n",
       "\n",
       "                                               probs  \n",
       "0  [0.001480210805311799, 0.9981943964958191, 0.0...  \n",
       "1  [2.457024311297573e-05, 0.999975323677063, 5.4...  \n",
       "2  [0.08060691505670547, 0.873210072517395, 0.046...  \n",
       "3  [2.004333810035064e-09, 1.0, 6.101986537582205...  \n",
       "4  [0.013884089887142181, 0.9833231568336487, 0.0...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prediction\"] = predictions\n",
    "df[\"probs\"] = probabilities\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cal_margin_sampling(y_pred_prob):\n",
    "    return np.diff(-np.sort(y_pred_prob)[:, ::-1][:, :2])\n",
    "\n",
    "def calc_entropy(y_pred_prob):\n",
    "    return -np.nansum(np.multiply(y_pred_prob, np.log(y_pred_prob)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.vstack(df.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ms\"] = cal_margin_sampling(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"en\"] = calc_entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>img_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_gt</th>\n",
       "      <th>original</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probs</th>\n",
       "      <th>ms</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1471-2121-3-29-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of a S2 cell transfect...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.004090134, -0.1427809, -0.1732117, -0.1795...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.001480210805311799, 0.9981943964958191, 0.0...</td>\n",
       "      <td>0.996714</td>\n",
       "      <td>1.406192e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1471-2172-7-1-4.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Distribution of Bu-1 +  cells . PALT is seen b...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.7017001, -0.077621244, -0.13674453, -0.0627...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[2.457024311297573e-05, 0.999975323677063, 5.4...</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>2.863747e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1471-2180-10-283-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Merged image of the phase contrast and fluores...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.11191165, -0.17719942, -0.15846144, -0.137...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.08060691505670547, 0.873210072517395, 0.046...</td>\n",
       "      <td>0.792603</td>\n",
       "      <td>4.633903e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1471-2180-5-17-9.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>552.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>An epifluorescence image of  Thermus aquaticus .,</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[1.7194173, -0.08525187, -0.12554392, -0.05411...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[2.004333810035064e-09, 1.0, 6.101986537582205...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.030027e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1471-2199-11-11-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of tagged-NrdB cells ....</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.18778822, -0.09744128, -0.14088048, -0.1344...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.013884089887142181, 0.9833231568336487, 0.0...</td>\n",
       "      <td>0.969439</td>\n",
       "      <td>9.234295e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img                                           img_path  \\\n",
       "0    1471-2121-3-29-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "1     1471-2172-7-1-4.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "2  1471-2180-10-283-1.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "3    1471-2180-5-17-9.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "4   1471-2199-11-11-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "\n",
       "   width  height    label  source  \\\n",
       "0  600.0   541.0  mic.flu  clef13   \n",
       "1  600.0   600.0  mic.flu  clef13   \n",
       "2  600.0   444.0  mic.flu  clef13   \n",
       "3  552.0   548.0  mic.flu  clef13   \n",
       "4  600.0   576.0  mic.flu  clef13   \n",
       "\n",
       "                                             caption  is_gt original  \\\n",
       "0  Fluorescence microscopy of a S2 cell transfect...   True     DMFL   \n",
       "1  Distribution of Bu-1 +  cells . PALT is seen b...   True     DMFL   \n",
       "2  Merged image of the phase contrast and fluores...   True     DMFL   \n",
       "3  An epifluorescence image of  Thermus aquaticus .,   True     DMFL   \n",
       "4  Fluorescence microscopy of tagged-NrdB cells ....   True     DMFL   \n",
       "\n",
       "  split_set                                           features prediction  \\\n",
       "0     TRAIN  [-0.004090134, -0.1427809, -0.1732117, -0.1795...    mic.flu   \n",
       "1     TRAIN  [0.7017001, -0.077621244, -0.13674453, -0.0627...    mic.flu   \n",
       "2     TRAIN  [-0.11191165, -0.17719942, -0.15846144, -0.137...    mic.flu   \n",
       "3     TRAIN  [1.7194173, -0.08525187, -0.12554392, -0.05411...    mic.flu   \n",
       "4     TRAIN  [0.18778822, -0.09744128, -0.14088048, -0.1344...    mic.flu   \n",
       "\n",
       "                                               probs        ms            en  \n",
       "0  [0.001480210805311799, 0.9981943964958191, 0.0...  0.996714  1.406192e-02  \n",
       "1  [2.457024311297573e-05, 0.999975323677063, 5.4...  0.999951  2.863747e-04  \n",
       "2  [0.08060691505670547, 0.873210072517395, 0.046...  0.792603  4.633903e-01  \n",
       "3  [2.004333810035064e-09, 1.0, 6.101986537582205...  1.000000  4.030027e-08  \n",
       "4  [0.013884089887142181, 0.9833231568336487, 0.0...  0.969439  9.234295e-02  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=2, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "pca = PCA(n_components=2, random_state=random_state)\n",
    "pca.fit(np.vstack(df.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pca  = pca.transform(np.vstack(df.features))\n",
    "df[\"x_pca\"], df[\"y_pca\"] = embeddings_pca[:,0], embeddings_pca[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def calc_neighborhood_hit(df, x_col, y_col, n_neighbors=6,column_label='label'):    \n",
    "    projections = [[i, j] for (i, j) in zip(df[x_col], df[y_col])]\n",
    "    neigh = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ball_tree').fit(projections)    \n",
    "    n_hits = []\n",
    "    for neighborhood in neigh.kneighbors(projections, n_neighbors + 1, return_distance=False):\n",
    "        labels  = df.iloc[neighborhood][column_label].values\n",
    "        targets = [labels[0]] * (len(labels) - 1) \n",
    "        n_hit = np.mean(targets == labels[1:])\n",
    "        n_hits.append(n_hit)\n",
    "    return n_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# predictor.model.hparams\n",
    "\n",
    "df[\"hits\"] = calc_neighborhood_hit(df, \"x_pca\", \"y_pca\", n_neighbors=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>img_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>caption</th>\n",
       "      <th>is_gt</th>\n",
       "      <th>original</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probs</th>\n",
       "      <th>ms</th>\n",
       "      <th>en</th>\n",
       "      <th>x_pca</th>\n",
       "      <th>y_pca</th>\n",
       "      <th>hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1471-2121-3-29-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of a S2 cell transfect...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.004090134, -0.1427809, -0.1732117, -0.1795...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.001480210805311799, 0.9981943964958191, 0.0...</td>\n",
       "      <td>0.996714</td>\n",
       "      <td>1.406192e-02</td>\n",
       "      <td>4.251132</td>\n",
       "      <td>-1.009367</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1471-2172-7-1-4.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Distribution of Bu-1 +  cells . PALT is seen b...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.7017001, -0.077621244, -0.13674453, -0.0627...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[2.457024311297573e-05, 0.999975323677063, 5.4...</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>2.863747e-04</td>\n",
       "      <td>13.939093</td>\n",
       "      <td>-2.682397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1471-2180-10-283-1.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Merged image of the phase contrast and fluores...</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[-0.11191165, -0.17719942, -0.15846144, -0.137...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.08060691505670547, 0.873210072517395, 0.046...</td>\n",
       "      <td>0.792603</td>\n",
       "      <td>4.633903e-01</td>\n",
       "      <td>-0.888648</td>\n",
       "      <td>-0.570510</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1471-2180-5-17-9.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>552.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>An epifluorescence image of  Thermus aquaticus .,</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[1.7194173, -0.08525187, -0.12554392, -0.05411...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[2.004333810035064e-09, 1.0, 6.101986537582205...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.030027e-08</td>\n",
       "      <td>28.581532</td>\n",
       "      <td>-1.882622</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1471-2199-11-11-2.jpg</td>\n",
       "      <td>subfigure-classification/2013/train/DMFL/1471-...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>clef13</td>\n",
       "      <td>Fluorescence microscopy of tagged-NrdB cells ....</td>\n",
       "      <td>True</td>\n",
       "      <td>DMFL</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.18778822, -0.09744128, -0.14088048, -0.1344...</td>\n",
       "      <td>mic.flu</td>\n",
       "      <td>[0.013884089887142181, 0.9833231568336487, 0.0...</td>\n",
       "      <td>0.969439</td>\n",
       "      <td>9.234295e-02</td>\n",
       "      <td>1.939335</td>\n",
       "      <td>-1.219068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img                                           img_path  \\\n",
       "0    1471-2121-3-29-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "1     1471-2172-7-1-4.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "2  1471-2180-10-283-1.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "3    1471-2180-5-17-9.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "4   1471-2199-11-11-2.jpg  subfigure-classification/2013/train/DMFL/1471-...   \n",
       "\n",
       "   width  height    label  source  \\\n",
       "0  600.0   541.0  mic.flu  clef13   \n",
       "1  600.0   600.0  mic.flu  clef13   \n",
       "2  600.0   444.0  mic.flu  clef13   \n",
       "3  552.0   548.0  mic.flu  clef13   \n",
       "4  600.0   576.0  mic.flu  clef13   \n",
       "\n",
       "                                             caption  is_gt original  \\\n",
       "0  Fluorescence microscopy of a S2 cell transfect...   True     DMFL   \n",
       "1  Distribution of Bu-1 +  cells . PALT is seen b...   True     DMFL   \n",
       "2  Merged image of the phase contrast and fluores...   True     DMFL   \n",
       "3  An epifluorescence image of  Thermus aquaticus .,   True     DMFL   \n",
       "4  Fluorescence microscopy of tagged-NrdB cells ....   True     DMFL   \n",
       "\n",
       "  split_set                                           features prediction  \\\n",
       "0     TRAIN  [-0.004090134, -0.1427809, -0.1732117, -0.1795...    mic.flu   \n",
       "1     TRAIN  [0.7017001, -0.077621244, -0.13674453, -0.0627...    mic.flu   \n",
       "2     TRAIN  [-0.11191165, -0.17719942, -0.15846144, -0.137...    mic.flu   \n",
       "3     TRAIN  [1.7194173, -0.08525187, -0.12554392, -0.05411...    mic.flu   \n",
       "4     TRAIN  [0.18778822, -0.09744128, -0.14088048, -0.1344...    mic.flu   \n",
       "\n",
       "                                               probs        ms            en  \\\n",
       "0  [0.001480210805311799, 0.9981943964958191, 0.0...  0.996714  1.406192e-02   \n",
       "1  [2.457024311297573e-05, 0.999975323677063, 5.4...  0.999951  2.863747e-04   \n",
       "2  [0.08060691505670547, 0.873210072517395, 0.046...  0.792603  4.633903e-01   \n",
       "3  [2.004333810035064e-09, 1.0, 6.101986537582205...  1.000000  4.030027e-08   \n",
       "4  [0.013884089887142181, 0.9833231568336487, 0.0...  0.969439  9.234295e-02   \n",
       "\n",
       "       x_pca     y_pca      hits  \n",
       "0   4.251132 -1.009367  1.000000  \n",
       "1  13.939093 -2.682397  1.000000  \n",
       "2  -0.888648 -0.570510  0.666667  \n",
       "3  28.581532 -1.882622  1.000000  \n",
       "4   1.939335 -1.219068  1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29e56221297dcf76d1ff7e0087fc50901b5fe91198fb7405b22e2a39a8d782cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
