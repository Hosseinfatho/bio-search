{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from psycopg import connect\n",
    "from biosearch_core.db.model import ConnectionParams, params_from_env\n",
    "from biosearch_core.bilava import process_figures\n",
    "\n",
    "env_file = \"/home/jtt/kubernetes/envs/.env_training\"\n",
    "conn_params = params_from_env(env_file)\n",
    "\n",
    "parquets_dir = \"/media/cumulus/curation_data/modality_classifiers_production/data/cord19\"\n",
    "\n",
    "classifiers = {\n",
    "    # \"gel\": {\n",
    "    #     \"longname\": \"gel\",\n",
    "    #     \"shortname\": \"exp.gel\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/gel/efficientnet-b1_gel_0.pt\"\n",
    "    # },\n",
    "    \"higher-modality\": {\n",
    "        \"longname\": \"higher-modality\",\n",
    "        \"shortname\": \"\",\n",
    "        \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/higher-modality/efficientnet-b1_higher-modality_0.pt\"    \n",
    "    },\n",
    "    # \"experimental\": {\n",
    "    #     \"longname\": \"experimental\",\n",
    "    #     \"shortname\": \"exp\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/experimental/efficientnet-b1_experimental_0.pt\"    \n",
    "    # },\n",
    "    # \"experimental\": {\n",
    "    #     \"longname\": \"graphics\",\n",
    "    #     \"shortname\": \"gra\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/graphics/efficientnet-b1_graphics_0.pt\"    \n",
    "    # },\n",
    "    # \"microscopy\": {\n",
    "    #     \"longname\": \"microscopy\",\n",
    "    #     \"shortname\": \"mic\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/microscopy/efficientnet-b0_microscopy_0.pt\"    \n",
    "    # },\n",
    "    # \"electron\": {\n",
    "    #     \"longname\": \"electron\",\n",
    "    #     \"shortname\": \"mic.ele\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/electron/efficientnet-b1_electron_0.pt\"   \n",
    "    # },\n",
    "    # \"molecular\": {\n",
    "    #     \"longname\": \"molecular\",\n",
    "    #     \"shortname\": \"mol\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/molecular/efficientnet-b1_molecular_0.pt\"   \n",
    "    # },\n",
    "    # \"radiology\": {\n",
    "    #     \"longname\": \"radiology\",\n",
    "    #     \"shortname\": \"rad\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/radiology/efficientnet-b0_radiology_0.pt\"   \n",
    "    # },\n",
    "    # \"radiology\": {\n",
    "    #     \"longname\": \"photography\",\n",
    "    #     \"shortname\": \"pho\",\n",
    "    #     \"model\": \"/media/cumulus/curation_data/modality_classifiers_production/models/cord19/photography/resnet34_photography_0.pt\"   \n",
    "    # },\n",
    "}\n",
    "\n",
    "schemas_2_base_img_dir = {\n",
    "    \"training\": \"/media/cumulus/curation_data\",\n",
    "    \"cord19\": \"/media/cumulus/biosearch/cord19/to_predict\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "higher-modality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/content-onboarding/biosearch_core/bilava/process_figures.py:163: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_schema = sqlio.read_sql_query(query, conn)\n",
      "/home/jtt/repos/bio-search/content-onboarding/biosearch_core/bilava/process_figures.py:163: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_schema = sqlio.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (110395480 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (103275555 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (110395480 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/home/jtt/repos/bio-search/content-onboarding/.venv/lib/python3.10/site-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (103275555 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating active learning metrics\n",
      "projecting PCA\n",
      "devices available:  1\n",
      "running pca on gpu\n",
      "std::bad_alloc: out_of_memory: CUDA error at: /project/python/_skbuild/linux-x86_64-3.10/cmake-build/_deps/rmm-src/include/rmm/mr/device/cuda_memory_resource.hpp:70: cudaErrorMemoryAllocation out of memory\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def onboard_bilava_data_for_classifier(classifier, training_parques_dir, schemas_2_base_img_dir):\n",
    "    img_path_2_split_set = process_figures.fetch_split_set(classifier[\"longname\"], training_parques_dir)\n",
    "\n",
    "    with connect(conninfo=conn_params.conninfo(), autocommit=False) as conn:\n",
    "      df_db_figures = process_figures.fetch_from_db(conn, classifier[\"shortname\"], [\"training\", \"cord19\"])\n",
    "    \n",
    "    df_db_figures[\"split_set\"] = df_db_figures.apply(lambda x: img_path_2_split_set[x.uri][\"split_set\"] if x.uri in img_path_2_split_set else \"UNL\", axis=1)\n",
    "    # remove duplicated uri, most likely from training data\n",
    "    df_db_figures = df_db_figures.set_index(\"uri\")\n",
    "    df_db_figures = df_db_figures[~df_db_figures.index.duplicated()]\n",
    "    df_db_figures = df_db_figures.reset_index()\n",
    "\n",
    "    #return df_db_figures\n",
    "    df_processed = process_figures.calc_features_and_dim_values(classifier[\"model\"], df_db_figures, schemas_2_base_img_dir)    \n",
    "    return df_processed\n",
    "\n",
    "for key in classifiers.keys():\n",
    "    tic = time.time()\n",
    "    classifier = classifiers[key]\n",
    "    print(classifier['longname'])\n",
    "    \n",
    "    try:      \n",
    "      df = onboard_bilava_data_for_classifier(classifier, parquets_dir, schemas_2_base_img_dir)\n",
    "      df = df.astype({ 'id': int, 'status': int, 'width': int, 'height': int})\n",
    "      df.to_parquet(f\"./processed_{classifier['longname']}.parquet\")\n",
    "      toc = time.time() - tic\n",
    "      print(toc)\n",
    "    except Exception as e:\n",
    "       print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67ab03f1fe994222664e12fe4ba3f091b198cb5337ab8b92ec3312d3f3349829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
