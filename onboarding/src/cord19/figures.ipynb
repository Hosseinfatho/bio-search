{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from figure import Figure, Label, Observation\n",
    "import numpy as np\n",
    "from document import Cord19Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vil_files_path = Path('/Users/jtrell2/data/biocuration/vil-al-interface/files/cord19')\n",
    "all_path = vil_files_path / 'all.parquet'\n",
    "\n",
    "df_all = pd.read_parquet(all_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import every dataset that does not come from tinman or CORD19\n",
    "These datasets should be the easy ones as there is no associated document to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parquet_file = 'cord19_higher-modality_v1.parquet'\n",
    "\n",
    "tax_parquet_files = [\n",
    "  'cord19_experimental_v1.parquet',\n",
    "  'cord19_gel_v1.parquet',\n",
    "  'cord19_graphics_v1.parquet',\n",
    "  'cord19_microscopy_v1.parquet',\n",
    "  'cord19_molecular_v1.parquet',\n",
    "  'cord19_radiology_v1.parquet',\n",
    "  'cord19_electron_v1.parquet'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524139, 7)\n",
      "(527091, 7)\n"
     ]
    }
   ],
   "source": [
    "vil_files_path = Path('/Users/jtrell2/data/biocuration/vil-al-interface/files/cord19')\n",
    "df_all_images = pd.read_parquet(vil_files_path / all_parquet_file)\n",
    "\n",
    "# while exploring radiology images, I found some cases that were not in high modality.parquet\n",
    "# this is a mistake, so we need to fusion these images with the full_parquet data\n",
    "df_missing_from_full = pd.read_parquet('./missing_rad_ang.parquet')\n",
    "df_missing_from_full = df_missing_from_full[['img', 'label', 'caption', 'width', 'height', 'prediction', 'img_path']]\n",
    "\n",
    "df_all_images = pd.concat([df_all_images, df_missing_from_full])\n",
    "\n",
    "df_tinman = df_all_images[df_all_images.source == 'tinman']\n",
    "df_cord19 = df_all_images[df_all_images.source == 'cord19']\n",
    "df_others = df_all_images[~df_all_images.source.isin(['tinman', 'cord19'])]\n",
    "df_full_labels = pd.read_parquet(vil_files_path / 'all.parquet')\n",
    "print(df_full_labels.shape)\n",
    "\n",
    "df_full_labels = pd.concat([df_full_labels, df_missing_from_full])\n",
    "print(df_full_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "def connect(host: str, port: int, dbname: str, user: str, password: str) -> psycopg.Connection:\n",
    "  conn_str = f\"host={host} port={port} dbname={dbname} user={user} password={password}\"\n",
    "  return psycopg.connect(conn_str)\n",
    "\n",
    "env_file = '../../.env'\n",
    "config = dotenv_values(env_file)\n",
    "conn = connect(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "STATUS_LABELED = 0\n",
    "STATUS_UNLABELED = 1\n",
    "STATUS_LABELED_EXTERNALLY = 2\n",
    "\n",
    "TYPE_FIGURE = 0\n",
    "TYPE_SUBFIGURE = 1\n",
    "\n",
    "def insert_figure(conn, figure: Figure):\n",
    "  with conn.cursor() as cur:\n",
    "    sql_string = \"INSERT INTO dev.figures (name,caption,num_panes,fig_type,doc_id,status,uri,parent_id,width,height,coordinates,last_update_by,owner,migration_key,notes,labels,source) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) RETURNING id;\"\n",
    "    cur.execute(sql_string, figure.to_tuple())\n",
    "    conn.commit()\n",
    "    id = cur.fetchone()[0]\n",
    "    return id\n",
    "\n",
    "def insert_figures(db_params: dict, figures: list[Figure]):\n",
    "    try:\n",
    "      conn = connect(**db_params)\n",
    "      with conn.cursor() as cur:\n",
    "        with cur.copy(\"COPY dev.figures (name,caption,num_panes,fig_type,doc_id,status,uri,parent_id,width,height,coordinates,last_update_by,owner,migration_key,notes,labels,source) FROM STDIN\") as copy:\n",
    "          for f in figures:\n",
    "            copy.write_row(f.to_tuple())\n",
    "      conn.commit()\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "    finally:\n",
    "      conn.close()\n",
    "\n",
    "\n",
    "def get_full_labels(df) -> dict[str,str]:\n",
    "  labels = {}\n",
    "  for idx, el in df.iterrows():\n",
    "    labels[el.img_path] = el.label\n",
    "  return labels\n",
    "\n",
    "def insert_images_from_external_sources(config, df, full_labels):\n",
    "  figures = []\n",
    "\n",
    "  for idx, el in df.iterrows():\n",
    "    # df_all has the more detailed labels\n",
    "    label = full_labels[el.img_path]\n",
    "    figure = Figure(\n",
    "      id=None,\n",
    "      status=STATUS_LABELED_EXTERNALLY,\n",
    "      uri=el.img_path,\n",
    "      width=el.width,\n",
    "      height=el.height,\n",
    "      type=TYPE_SUBFIGURE,\n",
    "      name=el.name,\n",
    "      caption=None if el.caption == \"\" else el.caption,\n",
    "      num_panes=1,\n",
    "      doc_id=None,\n",
    "      parent_id=None,\n",
    "      coordinates=None,\n",
    "      last_update_by=None,\n",
    "      owner=None,\n",
    "      migration_key=None,\n",
    "      notes=None,\n",
    "      labels=[label],\n",
    "      source=el.source\n",
    "    )\n",
    "    figures.append(figure)\n",
    "  insert_figures(config, figures)\n",
    "\n",
    "\n",
    "def build_pmc_to_id_doc_dic(db_params) -> dict[str,str]:\n",
    "  \"\"\" Get a dictionary [pmcid, doc_id] to match figures to their corresponding\n",
    "      source documents \"\"\"\n",
    "  try:\n",
    "    conn = connect(**db_params)\n",
    "    with conn.cursor() as cur:\n",
    "      cur.execute(\"select id, pmcid from dev.documents where pmcid != ''\")\n",
    "      rows = cur.fetchall()\n",
    "      return {r[1]: r[0] for r in rows}\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    raise Exception(e)\n",
    "  finally:\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def extract_pmcid(img_path):\n",
    "  els = img_path.split('/')\n",
    "  return els[1]\n",
    "\n",
    "def insert_images_from_cord19(\n",
    "  config,\n",
    "  df,\n",
    "  full_labels: dict[str,str],\n",
    "  pmc2id_dict: dict[str, str]):\n",
    "\n",
    "  figures = []\n",
    "  for idx, el in df.iterrows():\n",
    "    label = full_labels[el.img_path]\n",
    "    pmcid = extract_pmcid(el.img_path)\n",
    "    doc_id = pmc2id_dict.get(pmcid, None)\n",
    "\n",
    "    if doc_id is None:\n",
    "      print(el.img_path)\n",
    "    \n",
    "    figure = Figure(\n",
    "      id=None,\n",
    "      status=STATUS_UNLABELED,\n",
    "      uri=el.img_path,\n",
    "      width=el.width,\n",
    "      height=el.height,\n",
    "      type=el.type,\n",
    "      name=el.name,\n",
    "      caption=None if el.caption == \"\" else el.caption,\n",
    "      num_panes=1,\n",
    "      doc_id=doc_id,\n",
    "      parent_id=el.parent_id,\n",
    "      coordinates=el.coordinates,\n",
    "      last_update_by=None,\n",
    "      owner=None,\n",
    "      migration_key=None,\n",
    "      notes=None,\n",
    "      labels=None, # all this data is unlabeled,\n",
    "      source=el.source\n",
    "    )\n",
    "    figures.append(figure)    \n",
    "  insert_figures(config, figures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_fig_uri_2_db_id(db_params: dict) -> dict[str, int]:\n",
    "  \"\"\" \n",
    "    Query the database for the insert figures and create a dictionary that \n",
    "    matches the figure path to the database id. We can just this match to \n",
    "    populate the figure id for the labels table.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    conn = connect(**db_params)\n",
    "    with conn.cursor() as cur:\n",
    "      cur.execute(\"select id, uri from dev.figures\")\n",
    "      rows = cur.fetchall()\n",
    "      return {r[1]: r[0] for r in rows}\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    raise Exception(e)\n",
    "  finally:\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def insert_labels_per_classifier(db_params: dict, labels: list[Label]):\n",
    "  try:\n",
    "    conn = connect(**db_params)\n",
    "    with conn.cursor() as cur:\n",
    "      with cur.copy(\"COPY dev.labels_cord19 (figure_id,classifier,label,prediction,features,pred_probs,margin_sample,entropy,split_set) FROM STDIN\") as copy:\n",
    "        for l in labels:\n",
    "          copy.write_row(l.to_tuple())\n",
    "    conn.commit()\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    raise Exception(e)\n",
    "  finally:\n",
    "    conn.close()  \n",
    "\n",
    "\n",
    "def insert_labels(db_params: dict, parquet_files: list[Path]):\n",
    "  uri2id = get_map_fig_uri_2_db_id(db_params)\n",
    "\n",
    "  for parquet_file in parquet_files:\n",
    "    classifier = parquet_file.name.split('_')[1]\n",
    "    print(f\"processing {classifier}\")\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    df = df[~df.source.isin(['tinman'])]\n",
    "\n",
    "    if df.shape[0] > 0:\n",
    "      df = df.replace({np.nan: None})\n",
    "      df[\"figure_id\"] = df.apply(lambda x: uri2id[x.img_path], axis=1)\n",
    "\n",
    "      if 'en_metric' not in df.columns:\n",
    "        df['en_metric'] = None\n",
    "      if 'ms_metric' not in df.columns:\n",
    "        df['ms_metric'] = None\n",
    "      \n",
    "      labels = []\n",
    "      for idx, el in df.iterrows():\n",
    "        label = Label(classifier=classifier,\n",
    "                      label=el.label,\n",
    "                      features=el.features,\n",
    "                      entropy=el.en_metric,\n",
    "                      figure_id=el.figure_id,\n",
    "                      margin_sample=el.ms_metric,\n",
    "                      pred_probs=el.pred_probs,\n",
    "                      prediction=el.prediction,\n",
    "                      split_set=el.split_set)\n",
    "        labels.append(label)\n",
    "      print(f\"inserting labels for {classifier} {len(labels)} rows\")\n",
    "      insert_labels_per_classifier(config, labels)\n",
    "    else:\n",
    "      print(f\"Nothing to insert for {classifier}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_modality_filename = 'cord19_higher-modality_v1.parquet'\n",
    "children_filenames = tax_parquet_files.copy()\n",
    "children_filenames.append(high_modality_filename)\n",
    "parquet_files = [vil_files_path / x for x in children_filenames]\n",
    "\n",
    "full_labels = get_full_labels(df_full_labels)\n",
    "# insert_images_from_external_sources(config, df_others, full_labels)\n",
    "# insert_labels(config, parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_images_from_external_sources(config, df_others, full_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert CORD19 figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_6982/2567895858.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cord19['path_length'] = df_cord19.apply(lambda x: calc_img_path_length(x.img_path), axis=1)\n",
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_6982/2567895858.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cord19['type'] = df_cord19.apply(lambda x: is_figure(x.path_length), axis=1)\n",
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_6982/2567895858.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cord19['parent_id'] = df_cord19.apply(lambda x: get_parent_image(x.img_path, x.type), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# from the uic dataset, figures have length 4 in image path and subfigures have length 5\n",
    "from typing import Optional\n",
    "\n",
    "def is_figure(splits: int) -> int:\n",
    "  if splits == 3:\n",
    "    return TYPE_FIGURE\n",
    "  if splits == 4:\n",
    "    return TYPE_FIGURE\n",
    "  elif splits == 5:\n",
    "    return TYPE_SUBFIGURE\n",
    "  else:\n",
    "    return -1\n",
    "\n",
    "def calc_img_path_length(img_path: str) -> int:\n",
    "  # supplementary material processed have an additional level to the structure\n",
    "  splits = img_path.split('/')\n",
    "  return len(splits) if 'supplementary' not in splits else len(splits) - 1\n",
    "\n",
    "def get_parent_image(img_path: str, type: int) -> str:\n",
    "  if type == TYPE_FIGURE:\n",
    "    return None\n",
    "  else:\n",
    "    if 'figsplit' in img_path:\n",
    "      return f\"{str(Path(img_path).parent)}.jpg\".replace(\"figsplit_\", \"\")\n",
    "    else:\n",
    "      return f\"{str(Path(img_path).parent)}.jpg\"\n",
    "\n",
    "df_cord19['path_length'] = df_cord19.apply(lambda x: calc_img_path_length(x.img_path), axis=1)\n",
    "df_cord19['type'] = df_cord19.apply(lambda x: is_figure(x.path_length), axis=1)\n",
    "df_cord19['parent_id'] = df_cord19.apply(lambda x: get_parent_image(x.img_path, x.type), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_6982/1065974785.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_figures['coordinates'] = None\n"
     ]
    }
   ],
   "source": [
    "# get the dictionary of documents for foreigin key\n",
    "pmc2docid_dict = build_pmc_to_id_doc_dic(config)\n",
    "# insert first the figures\n",
    "df_figures = df_cord19[df_cord19.type == TYPE_FIGURE]\n",
    "df_figures['coordinates'] = None\n",
    "insert_images_from_cord19(config, df_figures, full_labels, pmc2docid_dict)\n",
    "# map figure ids to replace the parent_id column\n",
    "img_path_2_id = get_map_fig_uri_2_db_id(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_6982/1397034814.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subfigures.parent_id = df_subfigures.apply(lambda x: img_path_2_id[x.parent_id], axis=1)\n",
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_6982/1397034814.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subfigures['coordinates'] = df_subfigures.apply(lambda x: coordinate_mapping.get(x.img_path, None), axis=1)\n"
     ]
    }
   ],
   "source": [
    "def get_coordinate_mapping(df, base_path: Path):\n",
    "  # match coordinates to subfigure img_path\n",
    "  subfigure_paths = list(set([f\"{Path(x).parent}\" for x in df.img_path]))\n",
    "\n",
    "  img_path_2_coordinates = {}\n",
    "  fails = []\n",
    "  for p in subfigure_paths:\n",
    "    filename = f\"{Path(p).name}.jpg.txt\"\n",
    "    try:\n",
    "      with open(base_path / p / filename, 'r') as f:\n",
    "        # ignore first and second lines\n",
    "        lines = f.readlines()[2:]\n",
    "        for idx, line in enumerate(lines):\n",
    "          line = line.replace(\"    \", \" \").replace(\"\\n\", \"\").strip()\n",
    "          line = line.split(' ')\n",
    "          line = [float(x) for x in line if x != '']\n",
    "          name = f\"{p}/{str(idx+1).zfill(3)}.jpg\"\n",
    "          img_path_2_coordinates[name] = line\n",
    "    except FileNotFoundError as error:\n",
    "      fails.append(p)\n",
    "  return img_path_2_coordinates\n",
    "\n",
    "\n",
    "base_path = '/Users/jtrell2/data/biocuration/'\n",
    "df_subfigures = df_cord19[df_cord19.type == TYPE_SUBFIGURE]\n",
    "coordinate_mapping = get_coordinate_mapping(df_subfigures, Path(base_path))\n",
    "df_subfigures.parent_id = df_subfigures.apply(lambda x: img_path_2_id[x.parent_id], axis=1)\n",
    "df_subfigures['coordinates'] = df_subfigures.apply(lambda x: coordinate_mapping.get(x.img_path, None), axis=1)\n",
    "insert_images_from_cord19(config, df_subfigures, full_labels, pmc2docid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert tinman images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tinman/pIDRD_27_1765432/IDRD_27_1765432.pdf',\n",
       " 'tinman/p32203189/32203189.pdf',\n",
       " 'tinman/pPMC6957273/PMC6957273.pdf',\n",
       " 'tinman/p32218151/32218151.pdf']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all of tinman are subfigures...\n",
    "\n",
    "# insert documents first\n",
    "from os import listdir, path\n",
    "from pathlib import Path\n",
    "\n",
    "tinman_base_path = Path('/Users/jtrell2/data/biocuration/tinman')\n",
    "\n",
    "tinman_folders = [x for x in listdir(tinman_base_path) if path.isdir(tinman_base_path / x) ]\n",
    "tinman_docs = [str(Path('tinman') / x / x[1:]) + \".pdf\" for x in tinman_folders]\n",
    "tinman_docs[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def get_metadata(id, uri, dictionary, is_pmc):\n",
    "  data = dictionary['result'][id]\n",
    "  authors = [x['name'] for x in data['authors']]\n",
    "  try:\n",
    "    publication_date = datetime.strptime(data['epubdate'], '%Y %b %d')\n",
    "  except:\n",
    "    try:\n",
    "      publication_date = datetime.strptime(data['pubdate'], '%Y %b')\n",
    "    except:\n",
    "      publication_date = datetime.strptime(data['pubdate'], '%Y %b %d')\n",
    "  journal = data['fulljournalname']\n",
    "  title = data['title']\n",
    "\n",
    "  pubmed_id = None\n",
    "  pmcid = None\n",
    "  doi = None\n",
    "  for articleid in data[\"articleids\"]:\n",
    "    if articleid['idtype'] == 'pmid':\n",
    "      pubmed_id = articleid['value']\n",
    "    if is_pmc:\n",
    "      if articleid['idtype'] == 'pmcid':\n",
    "        pmcid = articleid['value']\n",
    "    else:\n",
    "      if articleid['idtype'] == 'pmc':\n",
    "        pmcid = articleid['value']\n",
    "    if articleid['idtype'] == 'doi':\n",
    "      doi = articleid['value']\n",
    "  project = 'animo'\n",
    "  license = None\n",
    "  uri = uri\n",
    "\n",
    "  return {\n",
    "    'authors': authors,\n",
    "    'publication_date': publication_date,\n",
    "    'journal': journal,\n",
    "    'title': title,\n",
    "    'abstract': None,\n",
    "    'project': project,\n",
    "    'license': None,\n",
    "    'uri': str(uri),\n",
    "    'pmcid': pmcid,\n",
    "    'pubmed_id': pubmed_id,\n",
    "    'doi': doi,\n",
    "    'cord_uid': None,\n",
    "    'notes': None,\n",
    "    'status': 'IMPORTED',\n",
    "    'modalities': None\n",
    "  }\n",
    "\n",
    "\n",
    "tinman_docs_to_insert = []\n",
    "pubmed_ids = []\n",
    "pubmed_paths = []\n",
    "pmcids = []\n",
    "pmcs_paths = []\n",
    "others = []\n",
    "other_paths = []\n",
    "\n",
    "for doc in tinman_docs:\n",
    "  doc_path = Path(doc)\n",
    "  doc_name = doc_path.name[:-4]\n",
    "  if 'PMC' in doc_name:\n",
    "    pmcids.append(doc_name[3:])\n",
    "    pmcs_paths.append(doc_path)\n",
    "  elif len(doc_name) == 8:\n",
    "    pubmed_ids.append(doc_name)\n",
    "    pubmed_paths.append(doc_path)\n",
    "  else:\n",
    "    others.append(doc_name)\n",
    "    other_paths.append(doc_path)\n",
    "\n",
    "concat_pubmed_ids = ','.join(pubmed_ids)\n",
    "concat_pmcids = ','.join(pmcids)\n",
    "res_pubmedids = requests.get(f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&id={concat_pubmed_ids}&retmode=json')\n",
    "sleep(3)\n",
    "res_pmcids = requests.get(f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pmc&id={concat_pmcids}&retmode=json')\n",
    "\n",
    "dict_pubmed = res_pubmedids.json()\n",
    "dict_pmc = res_pmcids.json()\n",
    "\n",
    "documents = []\n",
    "for id, doc_path in zip(pubmed_ids, pubmed_paths):\n",
    "  try:\n",
    "    metadata = get_metadata(id, doc_path, dict_pubmed, False)\n",
    "    document = Cord19Document(**metadata)\n",
    "    if document.pmcid is not None:\n",
    "      document.pmcid = document.pmcid[3:]\n",
    "    documents.append(document)\n",
    "  except Exception as e:\n",
    "    print(id)\n",
    "    raise e\n",
    "\n",
    "for id, doc_path in zip(pmcids, pmcs_paths):\n",
    "  metadata = get_metadata(id, doc_path, dict_pmc, True)\n",
    "  metadata['pmcid'] = int(metadata['pmcid'][3:]) \n",
    "  document = Cord19Document(**metadata)\n",
    "  documents.append(document)\n",
    "\n",
    "for id, doc_path in zip(others, other_paths):\n",
    "  document = Cord19Document(\n",
    "    abstract=None,\n",
    "    authors=None,\n",
    "    journal=None,\n",
    "    title=id,\n",
    "    cord_uid=None,\n",
    "    doi=None,\n",
    "    license=None,\n",
    "    modalities=None,\n",
    "    notes=None,\n",
    "    pmcid=None,\n",
    "    publication_date=None,\n",
    "    project='animo',\n",
    "    pubmed_id=None,\n",
    "    repository=None,\n",
    "    uri=str(doc_path),\n",
    "    status='IMPORTED'\n",
    "  )\n",
    "  documents.append(document)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_documents_to_db(db_params: dict, documents: list[Cord19Document]):\n",
    "  try:\n",
    "    conn = connect(**db_params)\n",
    "    with conn.cursor() as cur:\n",
    "      with cur.copy(\"COPY dev.documents (title, authors, abstract, publication_date, pmcid, pubmed_id, journal, repository, project, license, status, uri, doi, notes) FROM STDIN\") as copy:\n",
    "        for d in documents:\n",
    "          copy.write_row(d.to_tuple())\n",
    "    conn.commit()\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "  finally:\n",
    "    conn.close()\n",
    "\n",
    "insert_documents_to_db(config, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32203189,32218151,15525531,32057769,31752552,25874557,12826015,26028575,32201080,12702662,11110798,16854972,25479419,10655217,25869670,32065055,26028574,25671546,25474681,25330189,25850673,25443298,25330323,25232734,24732978,24929033,25474470,24968003,25054285,24810406,25594177,25978500,24918786,25167143,25101958,32238078,32198713,11060233,17223323,32209118,25982859,32747622,25181289,32231345,25357003,31856610,25527285,25644702,11546739,19158391,11091073,24844228,25144461,25372608,32758183,24684930,10444073,12783803,32229605,24684931,24999833,32466694,26121959,32210742,32105468,32249956,25635455,12847081,10015631,25493563,25264253,25467982,25340742,32181901,25448701,25423491,32142938,25195067,25273556,25808955,24901837,16831832,25913400,26083785,32167166,25788288,32178970,25154398,12054525,32723915,25053664,25723162,25981666,25907097,24836561,25261697,32243911,32092911,32660153,32221306,26044593,26061275,10209262,26079877,32200634,32178593,32255491,18050498,26057124,32155444,25527286,32100877,32047258,25569233,25148942,32009228,32724125,16242019,31707866,25438941,32239522,25851606,26041936,10854422,25395666,11167013,32242950,25830239,32285106,17369360,19804759,24684932,25640076,25726726,25978409,25329901'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(pubmed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_images_from_tinman(\n",
    "  config,\n",
    "  df,\n",
    "  full_labels: dict[str,str]):\n",
    "\n",
    "  figures = []\n",
    "  for idx, el in df.iterrows():\n",
    "    label = full_labels[el.img_path]\n",
    "    pmcid = extract_pmcid(el.img_path)\n",
    "\n",
    "    if doc_id is None:\n",
    "      print(el.img_path)\n",
    "    \n",
    "    figure = Figure(\n",
    "      id=None,\n",
    "      status=STATUS_UNLABELED,\n",
    "      uri=el.img_path,\n",
    "      width=el.width,\n",
    "      height=el.height,\n",
    "      type=el.type,\n",
    "      name=el.name,\n",
    "      caption=None if el.caption == \"\" else el.caption,\n",
    "      num_panes=1,\n",
    "      doc_id=doc_id,\n",
    "      parent_id=el.parent_id,\n",
    "      coordinates=el.coordinates,\n",
    "      last_update_by=None,\n",
    "      owner=None,\n",
    "      migration_key=None,\n",
    "      notes=None,\n",
    "      labels=None, # all this data is unlabeled,\n",
    "      source=el.source\n",
    "    )\n",
    "    figures.append(figure)    \n",
    "  insert_figures(config, figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinman_figures = {}\n",
    "for idx, row in df_tinman.iterrows():\n",
    "  figure_path = f\"{Path(row.img_path).parent}.jpg\"\n",
    "  w, h = Image.open(base_path / figure_path).size\n",
    "  if figure_path not in tinman_figures:\n",
    "    tinman_figures[figure_path] = {\n",
    "      'img': figure_path.split('/')[-1],\n",
    "      'source': 'tinman',\n",
    "      'fig_type': TYPE_FIGURE,\n",
    "      'img_path': figure_path,\n",
    "      'label': None,\n",
    "      'split_set': None,\n",
    "      'features': None,\n",
    "      'prediction': None,\n",
    "      'width': w,\n",
    "      'height': h,\n",
    "      'caption': row.caption,\n",
    "      'ms_metric': None,\n",
    "      'en_metric': None,\n",
    "      'pred_probs': None\n",
    "    }\n",
    "\n",
    "tinman_figures = [tinman_figures[x] for x in tinman_figures]\n",
    "\n",
    "df_tinman_figures = pd.DataFrame(tinman_figures)\n",
    "df_tinman_subfigures = df_tinman.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>source</th>\n",
       "      <th>fig_type</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>caption</th>\n",
       "      <th>ms_metric</th>\n",
       "      <th>en_metric</th>\n",
       "      <th>pred_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_1.jpg</td>\n",
       "      <td>tinman</td>\n",
       "      <td>0</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9_1.jpg</td>\n",
       "      <td>tinman</td>\n",
       "      <td>0</td>\n",
       "      <td>tinman/pP31412244/P31412244/9_1.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>748</td>\n",
       "      <td>1264</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16_1.jpg</td>\n",
       "      <td>tinman</td>\n",
       "      <td>0</td>\n",
       "      <td>tinman/pP31412244/P31412244/16_1.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1025</td>\n",
       "      <td>1123</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7_1.jpg</td>\n",
       "      <td>tinman</td>\n",
       "      <td>0</td>\n",
       "      <td>tinman/pP31412244/P31412244/7_1.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>843</td>\n",
       "      <td>1058</td>\n",
       "      <td>Figure 3. The MLD of Atg2A Is Responsible for ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17_1.jpg</td>\n",
       "      <td>tinman</td>\n",
       "      <td>0</td>\n",
       "      <td>tinman/pP31412244/P31412244/17_1.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1024</td>\n",
       "      <td>1239</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        img  source  fig_type                              img_path label  \\\n",
       "0   5_1.jpg  tinman         0   tinman/pP31412244/P31412244/5_1.jpg  None   \n",
       "1   9_1.jpg  tinman         0   tinman/pP31412244/P31412244/9_1.jpg  None   \n",
       "2  16_1.jpg  tinman         0  tinman/pP31412244/P31412244/16_1.jpg  None   \n",
       "3   7_1.jpg  tinman         0   tinman/pP31412244/P31412244/7_1.jpg  None   \n",
       "4  17_1.jpg  tinman         0  tinman/pP31412244/P31412244/17_1.jpg  None   \n",
       "\n",
       "  split_set features prediction  width  height  \\\n",
       "0      None     None       None    860     860   \n",
       "1      None     None       None    748    1264   \n",
       "2      None     None       None   1025    1123   \n",
       "3      None     None       None    843    1058   \n",
       "4      None     None       None   1024    1239   \n",
       "\n",
       "                                             caption ms_metric en_metric  \\\n",
       "0  Figure 2. Atg2A Localizes to MAM upon Autophag...      None      None   \n",
       "1                no caption extracted for this image      None      None   \n",
       "2                no caption extracted for this image      None      None   \n",
       "3  Figure 3. The MLD of Atg2A Is Responsible for ...      None      None   \n",
       "4                no caption extracted for this image      None      None   \n",
       "\n",
       "  pred_probs  \n",
       "0       None  \n",
       "1       None  \n",
       "2       None  \n",
       "3       None  \n",
       "4       None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(860, 860)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "base_path = Path('/Users/jtrell2/data/biocuration')\n",
    "img = Image.open(base_path / 'tinman/pP31412244/P31412244/5_1.jpg')\n",
    "print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>source</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>caption</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>ms_metric</th>\n",
       "      <th>en_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5dfba084f5d15939fd4cade2</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1/001.jpg</td>\n",
       "      <td>mic</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.28341508, 0.0, 2.1752567, 4.174899, 0.79845...</td>\n",
       "      <td>exp</td>\n",
       "      <td>314</td>\n",
       "      <td>196</td>\n",
       "      <td>[0.9546151161193848, 0.005383739247918129, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5dfba084f5d15939fd4cade3</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1/004.jpg</td>\n",
       "      <td>mic</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.059746925, 0.0, 2.9038484, 2.5127983, 0.080...</td>\n",
       "      <td>exp</td>\n",
       "      <td>542</td>\n",
       "      <td>531</td>\n",
       "      <td>[0.5600640773773193, 0.016546688973903656, 0.3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5dfba084f5d15939fd4cade4</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1/003.jpg</td>\n",
       "      <td>gra</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.14466317, 1.8963909, 1.6162982, 0.9271355, ...</td>\n",
       "      <td>gra</td>\n",
       "      <td>209</td>\n",
       "      <td>310</td>\n",
       "      <td>[0.019948463886976242, 0.9020611047744751, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5dfba084f5d15939fd4cade8</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/9_1/007.jpg</td>\n",
       "      <td>gra</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.3676869, 4.7407584, 0.52103585, 0.18581437,...</td>\n",
       "      <td>gra</td>\n",
       "      <td>248</td>\n",
       "      <td>251</td>\n",
       "      <td>[5.356776711096245e-08, 0.9984208345413208, 3....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5dfba084f5d15939fd4cadea</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/9_1/006.jpg</td>\n",
       "      <td>gra</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[1.0687255, 4.2336006, 0.37320167, 0.09526259,...</td>\n",
       "      <td>gra</td>\n",
       "      <td>253</td>\n",
       "      <td>286</td>\n",
       "      <td>[1.3379103380728452e-10, 0.9999992847442627, 9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        img  source                                 img_path  \\\n",
       "0  5dfba084f5d15939fd4cade2  tinman  tinman/pP31412244/P31412244/5_1/001.jpg   \n",
       "1  5dfba084f5d15939fd4cade3  tinman  tinman/pP31412244/P31412244/5_1/004.jpg   \n",
       "2  5dfba084f5d15939fd4cade4  tinman  tinman/pP31412244/P31412244/5_1/003.jpg   \n",
       "3  5dfba084f5d15939fd4cade8  tinman  tinman/pP31412244/P31412244/9_1/007.jpg   \n",
       "4  5dfba084f5d15939fd4cadea  tinman  tinman/pP31412244/P31412244/9_1/006.jpg   \n",
       "\n",
       "  label                                            caption split_set  \\\n",
       "0   mic  Figure 2. Atg2A Localizes to MAM upon Autophag...     TRAIN   \n",
       "1   mic  Figure 2. Atg2A Localizes to MAM upon Autophag...     TRAIN   \n",
       "2   gra  Figure 2. Atg2A Localizes to MAM upon Autophag...     TRAIN   \n",
       "3   gra                no caption extracted for this image     TRAIN   \n",
       "4   gra                no caption extracted for this image     TRAIN   \n",
       "\n",
       "                                            features prediction  width  \\\n",
       "0  [0.28341508, 0.0, 2.1752567, 4.174899, 0.79845...        exp    314   \n",
       "1  [0.059746925, 0.0, 2.9038484, 2.5127983, 0.080...        exp    542   \n",
       "2  [0.14466317, 1.8963909, 1.6162982, 0.9271355, ...        gra    209   \n",
       "3  [0.3676869, 4.7407584, 0.52103585, 0.18581437,...        gra    248   \n",
       "4  [1.0687255, 4.2336006, 0.37320167, 0.09526259,...        gra    253   \n",
       "\n",
       "   height                                         pred_probs  ms_metric  \\\n",
       "0     196  [0.9546151161193848, 0.005383739247918129, 0.0...        NaN   \n",
       "1     531  [0.5600640773773193, 0.016546688973903656, 0.3...        NaN   \n",
       "2     310  [0.019948463886976242, 0.9020611047744751, 0.0...        NaN   \n",
       "3     251  [5.356776711096245e-08, 0.9984208345413208, 3....        NaN   \n",
       "4     286  [1.3379103380728452e-10, 0.9999992847442627, 9...        NaN   \n",
       "\n",
       "   en_metric  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tinman.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert labels after inserting all figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing experimental\n",
      "inserting labels for experimental 28491 rows\n",
      "processing gel\n",
      "Nothing to insert for gel\n",
      "processing graphics\n",
      "inserting labels for graphics 259044 rows\n",
      "processing microscopy\n",
      "inserting labels for microscopy 20997 rows\n",
      "processing molecular\n",
      "inserting labels for molecular 8788 rows\n",
      "processing radiology\n",
      "inserting labels for radiology 4615 rows\n",
      "processing electron\n",
      "inserting labels for electron 789 rows\n",
      "processing higher-modality\n",
      "inserting labels for higher-modality 520811 rows\n"
     ]
    }
   ],
   "source": [
    "insert_labels(config, parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/5t5m83qd44j2129ksjwbt3200000gn/T/ipykernel_86389/631137171.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cord19['document'] = df_cord19.apply(lambda x: x.img_path.split('/')[1], axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_cord19['document'] = df_cord19.apply(lambda x: x.img_path.split('/')[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: parent figures exist\n",
    "df_subfigures = df_cord19[df_cord19.type==1]\n",
    "\n",
    "base_path = Path('/Users/jtrell2/data/biocuration/')\n",
    "\n",
    "not_exist = []\n",
    "for idx, row in df_subfigures.iterrows():\n",
    "  p = base_path / row.parent_id\n",
    "  if not p.exists():\n",
    "    not_exist.append(p)\n",
    "\n",
    "assert len(not_exist) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>source</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>caption</th>\n",
       "      <th>split_set</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>ms_metric</th>\n",
       "      <th>en_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5dfba084f5d15939fd4cade2</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1/001.jpg</td>\n",
       "      <td>mic</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.28341508, 0.0, 2.1752567, 4.174899, 0.79845...</td>\n",
       "      <td>exp</td>\n",
       "      <td>314</td>\n",
       "      <td>196</td>\n",
       "      <td>[0.9546151161193848, 0.005383739247918129, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5dfba084f5d15939fd4cade3</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1/004.jpg</td>\n",
       "      <td>mic</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.059746925, 0.0, 2.9038484, 2.5127983, 0.080...</td>\n",
       "      <td>exp</td>\n",
       "      <td>542</td>\n",
       "      <td>531</td>\n",
       "      <td>[0.5600640773773193, 0.016546688973903656, 0.3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5dfba084f5d15939fd4cade4</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/5_1/003.jpg</td>\n",
       "      <td>gra</td>\n",
       "      <td>Figure 2. Atg2A Localizes to MAM upon Autophag...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.14466317, 1.8963909, 1.6162982, 0.9271355, ...</td>\n",
       "      <td>gra</td>\n",
       "      <td>209</td>\n",
       "      <td>310</td>\n",
       "      <td>[0.019948463886976242, 0.9020611047744751, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5dfba084f5d15939fd4cade8</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/9_1/007.jpg</td>\n",
       "      <td>gra</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[0.3676869, 4.7407584, 0.52103585, 0.18581437,...</td>\n",
       "      <td>gra</td>\n",
       "      <td>248</td>\n",
       "      <td>251</td>\n",
       "      <td>[5.356776711096245e-08, 0.9984208345413208, 3....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5dfba084f5d15939fd4cadea</td>\n",
       "      <td>tinman</td>\n",
       "      <td>tinman/pP31412244/P31412244/9_1/006.jpg</td>\n",
       "      <td>gra</td>\n",
       "      <td>no caption extracted for this image</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[1.0687255, 4.2336006, 0.37320167, 0.09526259,...</td>\n",
       "      <td>gra</td>\n",
       "      <td>253</td>\n",
       "      <td>286</td>\n",
       "      <td>[1.3379103380728452e-10, 0.9999992847442627, 9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        img  source                                 img_path  \\\n",
       "0  5dfba084f5d15939fd4cade2  tinman  tinman/pP31412244/P31412244/5_1/001.jpg   \n",
       "1  5dfba084f5d15939fd4cade3  tinman  tinman/pP31412244/P31412244/5_1/004.jpg   \n",
       "2  5dfba084f5d15939fd4cade4  tinman  tinman/pP31412244/P31412244/5_1/003.jpg   \n",
       "3  5dfba084f5d15939fd4cade8  tinman  tinman/pP31412244/P31412244/9_1/007.jpg   \n",
       "4  5dfba084f5d15939fd4cadea  tinman  tinman/pP31412244/P31412244/9_1/006.jpg   \n",
       "\n",
       "  label                                            caption split_set  \\\n",
       "0   mic  Figure 2. Atg2A Localizes to MAM upon Autophag...     TRAIN   \n",
       "1   mic  Figure 2. Atg2A Localizes to MAM upon Autophag...     TRAIN   \n",
       "2   gra  Figure 2. Atg2A Localizes to MAM upon Autophag...     TRAIN   \n",
       "3   gra                no caption extracted for this image     TRAIN   \n",
       "4   gra                no caption extracted for this image     TRAIN   \n",
       "\n",
       "                                            features prediction  width  \\\n",
       "0  [0.28341508, 0.0, 2.1752567, 4.174899, 0.79845...        exp    314   \n",
       "1  [0.059746925, 0.0, 2.9038484, 2.5127983, 0.080...        exp    542   \n",
       "2  [0.14466317, 1.8963909, 1.6162982, 0.9271355, ...        gra    209   \n",
       "3  [0.3676869, 4.7407584, 0.52103585, 0.18581437,...        gra    248   \n",
       "4  [1.0687255, 4.2336006, 0.37320167, 0.09526259,...        gra    253   \n",
       "\n",
       "   height                                         pred_probs  ms_metric  \\\n",
       "0     196  [0.9546151161193848, 0.005383739247918129, 0.0...        NaN   \n",
       "1     531  [0.5600640773773193, 0.016546688973903656, 0.3...        NaN   \n",
       "2     310  [0.019948463886976242, 0.9020611047744751, 0.0...        NaN   \n",
       "3     251  [5.356776711096245e-08, 0.9984208345413208, 3....        NaN   \n",
       "4     286  [1.3379103380728452e-10, 0.9999992847442627, 9...        NaN   \n",
       "\n",
       "   en_metric  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tinman is a bit different as the information for the PDF lies somewhere else...\n",
    "# i'd to insert those documents first... \n",
    "df_tinman.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('onboarding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57877b7f3feb1a7cf64d28d515d2ef487f55874f3acb52603d700000d2d9750c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
